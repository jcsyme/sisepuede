{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsyme/Documents/Projects/git_jbus/lac_decarbonization/python/data_structures.py:931: UserWarning: Invalid subsector attribute 'key_varreqs_partial'. Valid return type values are:'pycategory_primary', 'abv_subsector', 'sector', 'abv_sector', 'key_varreqs_all'\n",
      "  warnings.warn(f\"Invalid subsector attribute '{return_type}'. Valid return type values are:{valid_rts}\")\n"
     ]
    }
   ],
   "source": [
    "import model_attributes as ma\n",
    "from attribute_table import AttributeTable\n",
    "import importlib\n",
    "import math\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "import pyDOE2 as pyd\n",
    "import setup_analysis as sa\n",
    "import support_functions as sf\n",
    "import time\n",
    "import warnings\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsyme/Documents/Projects/git_jbus/lac_decarbonization/python/data_structures.py:931: UserWarning: Invalid subsector attribute 'key_varreqs_partial'. Valid return type values are:'pycategory_primary', 'abv_subsector', 'sector', 'abv_sector', 'key_varreqs_all'\n",
      "  warnings.warn(f\"Invalid subsector attribute '{return_type}'. Valid return type values are:{valid_rts}\")\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sa)\n",
    "def _setup_logger(namespace: str) -> None:\n",
    "    global logger\n",
    "    # configure\n",
    "    logging.basicConfig(\n",
    "        filename = \"/Users/jsyme/Desktop/tst.log\",\n",
    "        level = logging.DEBUG\n",
    "    )\n",
    "    logger = logging.getLogger(namespace)\n",
    "    # create console handler and set level to debug\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    # create formatter\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    # add formatter to ch\n",
    "    ch.setFormatter(formatter)\n",
    "    # add ch to logger\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 13:35:37,874 - INFO - test\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary\n",
    "# expand later to integrate strategy dimension\n",
    "def build_modvar_input_db_from_templates(\n",
    "    model_attributes: ma.ModelAttributes,\n",
    "    sectors: list, \n",
    "    region: str, \n",
    "    template_type: str,\n",
    "    repl_missing_with_base: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    ##  run some checksee\n",
    "    \n",
    "    # check region\n",
    "    region = region.lower()\n",
    "    if region not in model_attributes.dict_attributes[\"region\"].key_values:\n",
    "        valid_regions = sf.format_print_list(model_attributes.dict_attributes[\"region\"].key_values)\n",
    "        raise ValueError(f\"Invalid region '{region}' specified. Valid regions are {valid_regions}\")\n",
    "        \n",
    "    # check sectors\n",
    "    sectors_drop = [x for x in sectors if (x not in model_attributes.all_sectors)]\n",
    "    if len(sectors_drop) > 0:\n",
    "        secs_drop = sf.format_print_list(sectors_drop)\n",
    "        raise ValueError(f\"Invalid sectors {secs_drop} found. Valid sectors are {model_attributes.all_sectors}.\")\n",
    "    \n",
    "    \n",
    "    ##\n",
    "    ##  TEMP: 0 only\n",
    "    ##\n",
    "    strat_base = 0\n",
    "    sheet_base = f\"{model_attributes.dim_strategy_id}-{strat_base}\"\n",
    "    \n",
    "    strats_eval = [strat_base]\n",
    "    \n",
    "    df_out = []\n",
    "    \n",
    "        \n",
    "    for sec in sectors:\n",
    "        fp_templ = sa.excel_template_path(sec, region, template_type, True)\n",
    "        if not os.path.exists(fp_templ):\n",
    "            raise ValueError(f\"Error: path '{fp_templ}' to template not found.\")\n",
    "        # check available sheets and ensure baseline is available\n",
    "        sheets_avail = pd.ExcelFile(fp_templ).sheet_names\n",
    "        if sheet_base not in sheets_avail:\n",
    "             raise ValueError(f\"Baseline strategy sheet {sheet_base} not found in '{fp_templ}'. The template must have a sheet for the baseline strategy.\")\n",
    "        \n",
    "        \n",
    "        for strat in strats_eval:\n",
    "            sheet = f\"{model_attributes.dim_strategy_id}-{strat}\"\n",
    "            if not sheet in sheets_avail:\n",
    "                msg = f\"Sheet {sheet} not found in '{fp_templ}'. Check the template.\"\n",
    "                if repl_missing_with_base:\n",
    "                    warnings.warn(f\"{msg}. The baseline strategy will be used.\")\n",
    "                    sheet = sheet_base\n",
    "                else:\n",
    "                    raise ValueError(msg)\n",
    "            \n",
    "            # \n",
    "            df_tmp = pd.read_excel(fp_templ, sheet_name = sheet)\n",
    "            df_tmp[model_attributes.dim_strategy_id] = strat\n",
    "            \n",
    "            #\n",
    "            #   ADD CHECKS FOR TIME PERIODS\n",
    "            #\n",
    "            \n",
    "            \n",
    "            #\n",
    "            #   ADD DIFFERENT STEPS FOR NON-BASELINE STRATEGY\n",
    "            #\n",
    "            \n",
    "            if len(df_out) == 0:\n",
    "                df_out.append(df_tmp)\n",
    "            else:\n",
    "                df_out.append(df_tmp[df_out[0].columns])\n",
    "                \n",
    "    df_out = pd.concat(df_out, axis = 0).sort_values(by = [\"subsector\", \"variable\"]).reset_index(drop = True)\n",
    "        \n",
    "    return df_out\n",
    "        \n",
    "# function to convert a model variable input database into a simple projection input dataframe\n",
    "def build_basic_df_from_modvar_inputs(\n",
    "    model_attributes: ma.ModelAttributes, \n",
    "    df_mv: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        build_basic_df_from_modvar_inputs will take a model input database and transform it (under baseline assumptions) into a projection dataframe.\n",
    "\n",
    "        - model_attributes: a ModelAttributes class\n",
    "\n",
    "        - df_mv: a dataframe of model variables\n",
    "    \"\"\"\n",
    "\n",
    "    df_mv_out = df_mv[[str(x) for x in model_attributes.get_time_periods()[0]]].transpose().reset_index(drop = True)\n",
    "    var_fields = list(df_mv[\"variable\"])\n",
    "    df_mv_out.rename(columns = dict(zip([(x) for x in range(len(df_mv_out.columns))], var_fields)), inplace = True)\n",
    "\n",
    "    df_mv_out[model_attributes.dim_time_period] = list(range(len(df_mv_out)))\n",
    "    var_fields.sort()\n",
    "\n",
    "    return df_mv_out[[model_attributes.dim_time_period] + var_fields]\n",
    "\n",
    "region = \"argentina\"\n",
    "# everything\n",
    "df_tmp = build_modvar_input_db_from_templates(sa.model_attributes, [\"Socioeconomic\", \"Circular Economy\", \"AFOLU\", \"IPPU\", \"Energy\"], region, \"demo\")       \n",
    "#df_mv_out = build_basic_df_from_modvar_inputs(sa.model_attributes, df_mv_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 14), match='strategy-40932'>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fp_read = sa.excel_template_path(\"AFOLU\", \"argentina\", \"demo\", True)\n",
    "#pd.read_excel(fp_read, sheet_name = None)\n",
    "regex_max = re.compile(\"strategy-(\\d*$)\")\n",
    "\n",
    "regex_max.match(\"strategy-40932\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dimension 'future_id': valid dimensions are 'time_period', 'strategy_id'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-d655831e738d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_attributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_baseline_scenario_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"future_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Projects/git_jbus/lac_decarbonization/python/data_structures.py\u001b[0m in \u001b[0;36mget_baseline_scenario_id\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mfpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_print_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid dimension '{dim}': valid dimensions are {fpl}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;31m# get field to check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dimension 'future_id': valid dimensions are 'time_period', 'strategy_id'."
     ]
    }
   ],
   "source": [
    "sa.model_attributes.get_baseline_scenario_id(\"future_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (None, None, None, None, None)\n",
    "(a, b, c, d, e) = x\n",
    "\n",
    "all((1, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tmp = pd.read_csv(\"/Users/jsyme/Documents/Projects/FY20/SWCHE102-1000/git/MultiSector_LTS_Chile/ref/parameter_ranges.csv\")\n",
    "#df_tmp0 = df_tmp.copy()\n",
    "#dict_rnm = dict([(str(x), str(x - 2015)) for x in range(2015, 2051)])\n",
    "#dict_rnm.update({\"min_2050\": \"min_35\", \"max_2050\": \"max_35\", \"parameter\": \"variable\", \"parameter_constant_q\": \"uniform_scaling_q\"})\n",
    "#df_tmp.rename(columns = dict_rnm, inplace = True)\n",
    "\n",
    "##  split traj groups\n",
    "new_col_tg = []\n",
    "new_col_spec_type = []\n",
    "\n",
    "for i in range(len(df_tmp)):\n",
    "    vs = str(df_tmp[\"variable\"].iloc[i])\n",
    "    tg = None\n",
    "    spec = None\n",
    "    \n",
    "    if \"trajgroup\" in vs:\n",
    "        vsplit = vs.split(\"-\")\n",
    "        tg = int(vsplit[0].split(\"_\")[1])\n",
    "        check_spec_string = vsplit[1]\n",
    "    else:\n",
    "        check_spec_string = vs\n",
    "\n",
    "    if \"trajmax\" in check_spec_string:\n",
    "        spec = \"max\"\n",
    "    elif \"trajmin\" in check_spec_string:\n",
    "        spec = \"min\"\n",
    "    elif \"trajmix\" in check_spec_string:\n",
    "        spec = \"mix\"\n",
    "    elif \"lhs\" in (check_spec_string) and (tg != None):\n",
    "        spec = \"lhs\"\n",
    "    \n",
    "    new_col_tg.append(tg)\n",
    "    new_col_spec_type.append(spec)\n",
    "        \n",
    "df_tmp[\"variable_trajectory_group\"] = pd.Series(new_col_tg, dtype=pd.Int64Dtype())\n",
    "#df_tmp[\"trajgroup\"] = df_tmp[\"trajgroup\"].astype(int)\n",
    "df_tmp[\"variable_trajectory_group_trajectory_type\"] = new_col_spec_type\n",
    "\n",
    "\n",
    "##  update variables\n",
    "new_tg = max(df_tmp[~df_tmp[\"variable_trajectory_group\"].isna()][\"variable_trajectory_group\"]) + 1\n",
    "tgs = list(df_tmp[\"variable_trajectory_group\"].copy())\n",
    "tgspecs = list(df_tmp[\"variable_trajectory_group_trajectory_type\"].copy())\n",
    "var_list = list(df_tmp[\"variable\"].copy())\n",
    "dict_parameter_to_tg = {}\n",
    "dict_repl_tgt = {\"max\": \"trajectory_boundary_1\", \"min\": \"trajectory_boundary_0\"}\n",
    "\n",
    "for i in range(len(df_tmp)):\n",
    "    tg = str(df_tmp[\"variable_trajectory_group\"].iloc[i])\n",
    "    tgspec = str(df_tmp[\"variable_trajectory_group_trajectory_type\"].iloc[i])\n",
    "    vs = str(df_tmp[\"variable\"].iloc[i])\n",
    "    \n",
    "    if (tgspec != \"<NA>\") & (tgspec != \"None\"):\n",
    "        if tg not in [\"<NA>\", \"None\"]:\n",
    "            # drop the group/remove the trajmax/min/mix\n",
    "            vs = vs.split(\"-\")[1]\n",
    "            new_tg_q = False\n",
    "        else:\n",
    "            new_tg_q = True\n",
    "        \n",
    "        # check for current trajgroup type\n",
    "        for lev in [\"max\", \"mix\", \"min\"]:\n",
    "            str_check = f\"traj{lev}_\"\n",
    "            if str_check in vs:\n",
    "                vs = vs.replace(str_check, \"\")\n",
    "                \n",
    "        # update the variable list\n",
    "        var_list[i] = vs\n",
    "        # update indexing of trajectory groups\n",
    "        if new_tg_q:\n",
    "            if vs in dict_parameter_to_tg.keys():\n",
    "                tgs[i] = int(dict_parameter_to_tg[vs])\n",
    "            else:\n",
    "                dict_parameter_to_tg.update({vs: new_tg})\n",
    "                tgs[i] = new_tg\n",
    "                new_tg += 1\n",
    "\n",
    "df_tmp[\"variable\"] = var_list\n",
    "df_tmp[\"variable_trajectory_group\"] = tgs\n",
    "df_tmp = df_tmp[~df_tmp[\"variable\"].isin([\"lhs\"])]\n",
    "df_tmp[\"variable_trajectory_group_trajectory_type\"].replace(dict_repl_tgt, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        module\n",
       "\u001b[0;31mString form:\u001b[0m <module 're' from '/Users/jsyme/anaconda3/lib/python3.8/re.py'>\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/lib/python3.8/re.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Support for regular expressions (RE).\n",
       "\n",
       "This module provides regular expression matching operations similar to\n",
       "those found in Perl.  It supports both 8-bit and Unicode strings; both\n",
       "the pattern and the strings being processed can contain null bytes and\n",
       "characters outside the US ASCII range.\n",
       "\n",
       "Regular expressions can contain both special and ordinary characters.\n",
       "Most ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\n",
       "regular expressions; they simply match themselves.  You can\n",
       "concatenate ordinary characters, so last matches the string 'last'.\n",
       "\n",
       "The special characters are:\n",
       "    \".\"      Matches any character except a newline.\n",
       "    \"^\"      Matches the start of the string.\n",
       "    \"$\"      Matches the end of the string or just before the newline at\n",
       "             the end of the string.\n",
       "    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n",
       "             Greedy means that it will match as many repetitions as possible.\n",
       "    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n",
       "    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n",
       "    *?,+?,?? Non-greedy versions of the previous three special characters.\n",
       "    {m,n}    Matches from m to n repetitions of the preceding RE.\n",
       "    {m,n}?   Non-greedy version of the above.\n",
       "    \"\\\\\"     Either escapes special characters or signals a special sequence.\n",
       "    []       Indicates a set of characters.\n",
       "             A \"^\" as the first character indicates a complementing set.\n",
       "    \"|\"      A|B, creates an RE that will match either A or B.\n",
       "    (...)    Matches the RE inside the parentheses.\n",
       "             The contents can be retrieved or matched later in the string.\n",
       "    (?aiLmsux) The letters set the corresponding flags defined below.\n",
       "    (?:...)  Non-grouping version of regular parentheses.\n",
       "    (?P<name>...) The substring matched by the group is accessible by name.\n",
       "    (?P=name)     Matches the text matched earlier by the group named name.\n",
       "    (?#...)  A comment; ignored.\n",
       "    (?=...)  Matches if ... matches next, but doesn't consume the string.\n",
       "    (?!...)  Matches if ... doesn't match next.\n",
       "    (?<=...) Matches if preceded by ... (must be fixed length).\n",
       "    (?<!...) Matches if not preceded by ... (must be fixed length).\n",
       "    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n",
       "                       the (optional) no pattern otherwise.\n",
       "\n",
       "The special sequences consist of \"\\\\\" and a character from the list\n",
       "below.  If the ordinary character is not on the list, then the\n",
       "resulting RE will match the second character.\n",
       "    \\number  Matches the contents of the group of the same number.\n",
       "    \\A       Matches only at the start of the string.\n",
       "    \\Z       Matches only at the end of the string.\n",
       "    \\b       Matches the empty string, but only at the start or end of a word.\n",
       "    \\B       Matches the empty string, but not at the start or end of a word.\n",
       "    \\d       Matches any decimal digit; equivalent to the set [0-9] in\n",
       "             bytes patterns or string patterns with the ASCII flag.\n",
       "             In string patterns without the ASCII flag, it will match the whole\n",
       "             range of Unicode digits.\n",
       "    \\D       Matches any non-digit character; equivalent to [^\\d].\n",
       "    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n",
       "             bytes patterns or string patterns with the ASCII flag.\n",
       "             In string patterns without the ASCII flag, it will match the whole\n",
       "             range of Unicode whitespace characters.\n",
       "    \\S       Matches any non-whitespace character; equivalent to [^\\s].\n",
       "    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n",
       "             in bytes patterns or string patterns with the ASCII flag.\n",
       "             In string patterns without the ASCII flag, it will match the\n",
       "             range of Unicode alphanumeric characters (letters plus digits\n",
       "             plus underscore).\n",
       "             With LOCALE, it will match the set [0-9_] plus characters defined\n",
       "             as letters for the current locale.\n",
       "    \\W       Matches the complement of \\w.\n",
       "    \\\\       Matches a literal backslash.\n",
       "\n",
       "This module exports the following functions:\n",
       "    match     Match a regular expression pattern to the beginning of a string.\n",
       "    fullmatch Match a regular expression pattern to all of a string.\n",
       "    search    Search a string for the presence of a pattern.\n",
       "    sub       Substitute occurrences of a pattern found in a string.\n",
       "    subn      Same as sub, but also return the number of substitutions made.\n",
       "    split     Split a string by the occurrences of a pattern.\n",
       "    findall   Find all occurrences of a pattern in a string.\n",
       "    finditer  Return an iterator yielding a Match object for each match.\n",
       "    compile   Compile a pattern into a Pattern object.\n",
       "    purge     Clear the regular expression cache.\n",
       "    escape    Backslash all non-alphanumerics in a string.\n",
       "\n",
       "Each function other than purge and escape can take an optional 'flags' argument\n",
       "consisting of one or more of the following module constants, joined by \"|\".\n",
       "A, L, and U are mutually exclusive.\n",
       "    A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n",
       "                   match the corresponding ASCII character categories\n",
       "                   (rather than the whole Unicode categories, which is the\n",
       "                   default).\n",
       "                   For bytes patterns, this flag is the only available\n",
       "                   behaviour and needn't be specified.\n",
       "    I  IGNORECASE  Perform case-insensitive matching.\n",
       "    L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n",
       "    M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n",
       "                   as well as the string.\n",
       "                   \"$\" matches the end of lines (before a newline) as well\n",
       "                   as the end of the string.\n",
       "    S  DOTALL      \".\" matches any character at all, including the newline.\n",
       "    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n",
       "    U  UNICODE     For compatibility only. Ignored for string patterns (it\n",
       "                   is the default), and forbidden for bytes patterns.\n",
       "\n",
       "This module also defines an exception 'error'.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='09'>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "regex1 = re.compile(\"(\\d*$)\")\n",
    "regex1.match(\"09\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strr = re.compile(f\"{sa.model_attributes.dim_strategy_id}-(.*\\d$)\")\n",
    "strr.match(\"strategy_id-0\").groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 futures generated in 5.236482858657837 seconds.\n"
     ]
    }
   ],
   "source": [
    "##  class for sampling and generating experimental design\n",
    "class sampling_unit:\n",
    "\n",
    "    def __init__(self, df_var_def: pd.core.frame.DataFrame, dict_baseline_ids: dict, time_period_u0: int, field_strategy_id: str = \"strategy_id\", fan_function_specification: str = \"linear\"):\n",
    "\n",
    "        # set some attributes\n",
    "\n",
    "        self.field_strategy_id = field_strategy_id\n",
    "        self.time_period_end_certainty = time_period_u0\n",
    "        df_var = self.check_input_data_frame(df_var_def)\n",
    "        self.fields_id = self.get_id_fields(df_var)\n",
    "        self.field_min_scalar, self.field_max_scalar, self.time_period_scalar = self.get_scalar_time_period(df_var)\n",
    "        self.fields_time_periods, self.time_periods = self.get_time_periods(df_var)\n",
    "        self.variable_trajectory_group = self.get_trajgroup(df_var)\n",
    "        self.uncertainty_fan_function_parameters = self.get_fan_function_parameters(fan_function_specification)\n",
    "        self.uncertainty_ramp_vector = self.build_ramp_vector(self.uncertainty_fan_function_parameters)\n",
    "        \n",
    "        self.data_table, self.id_coordinates = self.check_scenario_variables(df_var, self.fields_id)\n",
    "        self.dict_id_values, self.dict_baseline_ids = self.get_scenario_values(self.data_table, self.fields_id, dict_baseline_ids)\n",
    "        self.num_scenarios = len(self.id_coordinates)\n",
    "        self.variable_specifications = self.get_all_vs(self.data_table )\n",
    "        self.dict_variable_info = self.get_variable_dictionary(self.data_table, self.fields_id, self.fields_time_periods, self.variable_specifications, self.field_max_scalar, self.field_min_scalar)\n",
    "        self.ordered_trajectory_arrays = self.get_ordered_trajectory_arrays(self.data_table, self.fields_id, self.fields_time_periods, self.variable_specifications)\n",
    "        self.scalar_diff_arrays = self.get_scalar_diff_arrays()\n",
    "        \n",
    "        # important components for different design ids + assessing uncertainty in lever acheivement\n",
    "        self.fields_order_strat_diffs = [x for x in self.fields_id if (x != self.field_strategy_id)] + [self.field_var_spec, self.field_trajgroup_spec]\n",
    "        self.xl_type, self.dict_strategy_info = self.infer_sampling_unit_type()\n",
    "\n",
    "        \n",
    "\n",
    "    # initialize some attributes\n",
    "    field_trajgroup = \"variable_trajectory_group\"\n",
    "    field_trajgroup_spec = \"variable_trajectory_group_trajectory_type\"\n",
    "    field_uniform_scaling_q = \"uniform_scaling_q\"\n",
    "    field_var_spec = \"variable\"\n",
    "    # maps internal name (key) to classification in the input data frame (value)\n",
    "    dict_required_tg_spec_fields = {\"mixing_trajectory\": \"mix\", \"trajectory_boundary_0\": \"trajectory_boundary_0\", \"trajectory_boundary_1\": \"trajectory_boundary_1\"}\n",
    "    required_tg_specs = list(dict_required_tg_spec_fields.values())#[dict_required_tg_spec_fields[x] for x in [\"mixing_trajectory\", \"boundary_trajectory_0\", \"boundary_trajectory_1\"]]\n",
    "\n",
    "\n",
    "    ##  functions to initialize attributes\n",
    "\n",
    "    def check_input_data_frame(self, df_in: pd.DataFrame):\n",
    "\n",
    "        # some standardized fields to require\n",
    "        fields_req = [self.field_strategy_id, self.field_trajgroup, self.field_trajgroup_spec, self.field_uniform_scaling_q, self.field_var_spec]\n",
    "        if len(set(fields_req) & set(df_in.columns)) < len(set(fields_req)):\n",
    "            fields_missing = list(set(fields_req) - (set(fields_req) & set(df_in.columns)))\n",
    "            fields_missing.sort()\n",
    "            str_missing = \", \".join([f\"'{x}'\" for x in fields_missing])\n",
    "            raise ValueError(f\"Error: one or more columns are missing from the data frame. Columns {str_missing} not found\")\n",
    "        elif (self.field_strategy_id in df_in.columns) and (\"_id\" not in self.field_strategy_id):\n",
    "            raise ValueError(f\"Error: the strategy field '{self.field_strategy_id}' must contain the substring '_id'. Check to ensure this substring is specified.\")\n",
    "\n",
    "        return df_in.drop_duplicates()\n",
    "\n",
    "\n",
    "    def check_scenario_variables(self, df_in: pd.DataFrame, fields_id: list):\n",
    "        tups_id = set([tuple(x) for x in np.array(df_in[fields_id])])\n",
    "        for tg_type in self.required_tg_specs:\n",
    "            df_check = df_in[df_in[self.field_trajgroup_spec] == tg_type]\n",
    "            for vs in list(df_check[self.field_var_spec].unique()):\n",
    "                tups_id = tups_id & set([tuple(x) for x in np.array(df_check[df_check[self.field_var_spec] == vs][fields_id])])\n",
    "        df_scen = pd.DataFrame(tups_id, columns = fields_id)\n",
    "        df_in = pd.merge(df_in, df_scen, how = \"inner\", on = fields_id)\n",
    "\n",
    "        return (df_in, tups_id)\n",
    "\n",
    "\n",
    "    def get_all_vs(self, df_in: pd.DataFrame):\n",
    "        if not self.field_var_spec in df_in.columns:\n",
    "            raise ValueError(f\"Field '{self.field_var_spec}' not found in data frame.\")\n",
    "        all_vs = list(df_in[self.field_var_spec].unique())\n",
    "        all_vs.sort()\n",
    "        return all_vs\n",
    "\n",
    "\n",
    "    def get_id_fields(self, df_in: pd.DataFrame):\n",
    "        fields_out = [x for x in df_in.columns if (\"_id\" in x)]\n",
    "        fields_out.sort()\n",
    "        if len(fields_out) == 0:\n",
    "            raise ValueError(f\"No id fields found in data frame.\")\n",
    "\n",
    "        return fields_out\n",
    "\n",
    "\n",
    "    def get_ordered_trajectory_arrays(self, df_in: pd.DataFrame, fields_id: list, fields_time_periods: list, variable_specifications: list):\n",
    "        # order trajectory arrays by id fields; used for quicker lhs application across id dimensions\n",
    "        dict_out = {}\n",
    "        for vs in variable_specifications:\n",
    "            df_cur_vs = df_in[df_in[self.field_var_spec].isin([vs])].sort_values(by = fields_id)\n",
    "\n",
    "            if self.variable_trajectory_group == None:\n",
    "                dict_out.update({(vs, None): {\"data\": np.array(df_cur_vs[fields_time_periods]), \"id_coordinates\": df_cur_vs[fields_id]}})\n",
    "            else:\n",
    "                for tgs in self.required_tg_specs:\n",
    "                    df_cur = df_cur_vs[df_cur_vs[self.field_trajgroup_spec] == tgs]\n",
    "                    dict_out.update({(vs, tgs): {\"data\": np.array(df_cur[fields_time_periods]), \"id_coordinates\": df_cur[fields_id]}})\n",
    "        return dict_out\n",
    "\n",
    "\n",
    "    def get_scalar_time_period(self, df_in:pd.DataFrame):\n",
    "        # determine min field/time period\n",
    "        field_min = [x for x in df_in.columns if \"min\" in x]\n",
    "        if len(field_min) == 0:\n",
    "            raise ValueError(\"No field associated with a minimum scalar value found in data frame.\")\n",
    "        else:\n",
    "            field_min = field_min[0]\n",
    "\n",
    "        # determine max field/time period\n",
    "        field_max = [x for x in df_in.columns if \"max\" in x]\n",
    "        if len(field_max) == 0:\n",
    "            raise ValueError(\"No field associated with a maximum scalar value found in data frame.\")\n",
    "        else:\n",
    "            field_max = field_max[0]\n",
    "\n",
    "        tp_min = int(field_min.split(\"_\")[1])\n",
    "        tp_max = int(field_max.split(\"_\")[1])\n",
    "        if (tp_min != tp_max) | (tp_min == None):\n",
    "            raise ValueError(f\"Fields '{tp_min}' and '{tp_max}' imply asymmetric final time periods.\")\n",
    "        else:\n",
    "            tp_out = tp_min\n",
    "\n",
    "        return (field_min, field_max, tp_out)\n",
    "\n",
    "\n",
    "    def get_scenario_values(self, df_in: pd.DataFrame, fields_id: list, dict_baseline_ids: dict):\n",
    "        # get scenario index values by scenario dimension\n",
    "        dict_id_values = {}\n",
    "        dict_id_baselines = dict_baseline_ids.copy()\n",
    "\n",
    "        for fld in fields_id:\n",
    "            dict_id_values.update({fld: list(df_in[fld].unique())})\n",
    "            dict_id_values[fld].sort()\n",
    "\n",
    "            # check if baseline for field is determined\n",
    "            if fld in dict_id_baselines.keys():\n",
    "                bv = int(dict_id_baselines[fld])\n",
    "\n",
    "                if bv not in dict_id_values[fld]:\n",
    "                    if fld == self.field_strategy_id:\n",
    "                        print(bv)\n",
    "                        raise ValueError(f\"Error: baseline {self.field_strategy_id} scenario index '{bv}' not found in the variable trajectory input sheet. Please ensure the basline strategy is specified correctly.\")\n",
    "                    else:\n",
    "                        msg_warning = f\"The baseline id for dimension {fld} not found. The experimental design will not include futures along this dimension of analysis.\"\n",
    "                        warnings.warn(msg_warning)\n",
    "            else:\n",
    "                # assume minimum >= 0\n",
    "                bv = min([x for x in dict_id_values[fld] if x >= 0])\n",
    "                dict_id_baselines.update({fld: bv})\n",
    "                msg_warning = f\"No baseline scenario index found for {fld}. It will be assigned to '{bv}', the lowest non-negative integer.\"\n",
    "                warnings.warn(msg_warning)\n",
    "\n",
    "\n",
    "        return dict_id_values, dict_id_baselines\n",
    "\n",
    "\n",
    "    def get_time_periods(self, df_in: pd.DataFrame):\n",
    "        fields_time_periods = [x for x in df_in.columns if x.isnumeric()]\n",
    "        fields_time_periods = [x for x in fields_time_periods if int(x) == float(x)]\n",
    "        if len(fields_time_periods) == 0:\n",
    "            raise ValueError(\"No time periods found in data frame.\")\n",
    "        else:\n",
    "            time_periods = [int(x) for x in fields_time_periods]\n",
    "\n",
    "        time_periods.sort()\n",
    "        fields_time_periods = [str(x) for x in time_periods]\n",
    "\n",
    "        return (fields_time_periods, time_periods)\n",
    "\n",
    "    # get the trajectory group for the sampling unit\n",
    "    def get_trajgroup(self, df_in: pd.DataFrame):\n",
    "        if not self.field_trajgroup in df_in.columns:\n",
    "            raise ValueError(f\"Field '{self.field_trajgroup}' not found in data frame.\")\n",
    "        # determine if this is associated with a trajectory group\n",
    "        if len(df_in[~df_in[self.field_trajgroup].isna()]) > 0:\n",
    "            return int(list(df_in[self.field_trajgroup].unique())[0])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # the variable dictionary includes information on sampling ranges for time period scalars, wether the variables should be scaled uniformly, and the trajectories themselves\n",
    "    def get_variable_dictionary(\n",
    "        self, \n",
    "        df_in: pd.DataFrame, \n",
    "        fields_id: list, \n",
    "        fields_time_periods: list,\n",
    "        variable_specifications: list,\n",
    "        field_max: str,\n",
    "        field_min: str\n",
    "    ):\n",
    "        dict_var_info = {}\n",
    "\n",
    "        if self.variable_trajectory_group != None:\n",
    "            tgs_loops = self.required_tg_specs\n",
    "        else:\n",
    "            tgs_loops = [None]\n",
    "\n",
    "        for vs in variable_specifications:\n",
    "            for tgs in tgs_loops:\n",
    "                if tgs == None:\n",
    "                    df_cur = sf.subset_df(df_in, {self.field_var_spec: vs})\n",
    "                else:\n",
    "                    df_cur = sf.subset_df(df_in, {self.field_var_spec: vs, self.field_trajgroup_spec: tgs})\n",
    "                    \n",
    "                dict_vs = {\n",
    "                    \"max_scalar\": sf.build_dict(df_cur[fields_id + [field_max]]),\n",
    "                    \"min_scalar\": sf.build_dict(df_cur[fields_id + [field_min]]),\n",
    "                    \"uniform_scaling_q\": sf.build_dict(df_cur[fields_id + [self.field_uniform_scaling_q]]),\n",
    "                    \"trajectories\": sf.build_dict(df_cur[fields_id + fields_time_periods], (len(self.fields_id), len(self.fields_time_periods)))}\n",
    "\n",
    "                dict_var_info.update({(vs, tgs): dict_vs})\n",
    "\n",
    "        return dict_var_info\n",
    "\n",
    "    # determine if the sampling unit represents a strategy (L) or an uncertainty (X)\n",
    "    def infer_sampling_unit_type(self, thresh: float = (10**(-12))):\n",
    "        fields_id_no_strat = [x for x in self.fields_id if (x != self.field_strategy_id)]\n",
    "\n",
    "        strat_base = self.dict_baseline_ids[self.field_strategy_id]\n",
    "        strats_not_base = [x for x in self.dict_id_values[self.field_strategy_id] if (x != strat_base)]\n",
    "        fields_ext = [self.field_var_spec, self.field_trajgroup_spec] + self.fields_id + self.fields_time_periods\n",
    "        fields_ext = [x for x in fields_ext if (x != self.field_strategy_id)]\n",
    "        fields_merge = [x for x in fields_ext if (x not in self.fields_time_periods)]\n",
    "        # get the baseline strategy specification + set a renaming dictionary for merges\n",
    "        df_base = self.data_table[self.data_table[self.field_strategy_id] == strat_base][fields_ext].sort_values(by = self.fields_order_strat_diffs).reset_index(drop = True)\n",
    "        arr_base = np.array(df_base[self.fields_time_periods])\n",
    "        fields_base = list(df_base.columns)\n",
    "\n",
    "        dict_out = {\n",
    "            \"baseline_strategy_data_table\": df_base, \n",
    "            \"baseline_strategy_array\": arr_base,\n",
    "            \"difference_arrays_by_strategy\": {}\n",
    "        }\n",
    "\n",
    "        dict_diffs = {}\n",
    "        strategy_q = False\n",
    "\n",
    "        for strat in strats_not_base:\n",
    "\n",
    "            df_base = pd.merge(df_base, self.data_table[self.data_table[self.field_strategy_id] == strat][fields_ext], how = \"inner\", on = fields_merge, suffixes = (None, \"_y\"))\n",
    "            df_base.sort_values(by = self.fields_order_strat_diffs, inplace = True)\n",
    "            arr_cur = np.array(df_base[[(x + \"_y\") for x in self.fields_time_periods]])\n",
    "            arr_diff = arr_cur - arr_base\n",
    "            dict_diffs.update({strat: arr_diff})\n",
    "            df_base = df_base[fields_base]\n",
    "\n",
    "            if max(np.abs(arr_diff.flatten())) > thresh:\n",
    "                strategy_q = True\n",
    "\n",
    "        if strategy_q:\n",
    "            dict_out.update({\"difference_arrays_by_strategy\": dict_diffs})\n",
    "            type_out = \"L\"\n",
    "        else:\n",
    "            type_out = \"X\"\n",
    "\n",
    "        return type_out, dict_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##  operational functions\n",
    "\n",
    "    def get_scalar_diff_arrays(self):\n",
    "\n",
    "        tp_end = self.fields_time_periods[-1]\n",
    "        dict_out = {}\n",
    "\n",
    "        for vs in self.variable_specifications:\n",
    "            if self.variable_trajectory_group != None:\n",
    "                tgs_loops = self.required_tg_specs\n",
    "            else:\n",
    "                tgs_loops = [None]\n",
    "            for tgs in tgs_loops:\n",
    "                # get the vector (dim is by scenario, sorted by self.fields_id )\n",
    "                vec_tp_end = self.ordered_trajectory_arrays[(vs, tgs)][\"data\"][:,-1]\n",
    "                tups_id_coords = [tuple(x) for x in np.array(self.ordered_trajectory_arrays[(vs, tgs)][\"id_coordinates\"])]\n",
    "                # order the max/min scalars\n",
    "                vec_scale_max = np.array([self.dict_variable_info[(vs, tgs)][\"max_scalar\"][x] for x in tups_id_coords])\n",
    "                vec_scale_min = np.array([self.dict_variable_info[(vs, tgs)][\"min_scalar\"][x] for x in tups_id_coords])\n",
    "\n",
    "                # difference, in final time period, between scaled value and baseline value-dimension is # of scenarios\n",
    "                dict_tp_end_delta = {\n",
    "                    \"max_tp_end_delta\": vec_tp_end*(vec_scale_max - 1),\n",
    "                    \"min_tp_end_delta\": vec_tp_end*(vec_scale_min - 1)\n",
    "                }\n",
    "\n",
    "                dict_out.update({(vs, tgs): dict_tp_end_delta})\n",
    "\n",
    "        return dict_out\n",
    "    \n",
    "    \n",
    "    def mix_tensors(self, vec_b0, vec_b1, vec_mix, constraints_mix: tuple = (0, 1)):\n",
    "\n",
    "        v_0 = np.array(vec_b0)\n",
    "        v_1 = np.array(vec_b1)\n",
    "        v_m = np.array(vec_mix)\n",
    "\n",
    "\n",
    "        if constraints_mix != None:\n",
    "            if constraints_mix[0] >= constraints_mix[1]:\n",
    "                raise ValueError(\"Constraints to the mixing vector should be passed as (min, max)\")\n",
    "            v_alpha = v_m.clip(*constraints_mix)\n",
    "        else:\n",
    "            v_alpha = np.array(vec_mix)\n",
    "\n",
    "        if len(v_alpha.shape) == 0:\n",
    "            v_alpha = float(v_alpha)\n",
    "            check_val = len(set([v_0.shape, v_1.shape]))\n",
    "        else:\n",
    "            check_val = len(set([v_0.shape, v_1.shape, v_alpha.shape]))\n",
    "\n",
    "        if check_val > 1:\n",
    "            raise ValueError(\"Incongruent shapes in mix_tensors\")\n",
    "\n",
    "        return v_0*(1 - v_alpha) + v_1*v_alpha\n",
    "\n",
    "    \n",
    "    def ordered_by_ota_from_fid_dict(self, dict_in: dict, key_tuple: tuple):\n",
    "        return np.array([dict_in[tuple(x)] for x in np.array(self.ordered_trajectory_arrays[key_tuple][\"id_coordinates\"])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## uncertainty fan functions\n",
    "    \n",
    "     # construct the \"ramp\" vector for uncertainties\n",
    "    def build_ramp_vector(self, tuple_param):\n",
    "\n",
    "        if tuple_param == None:\n",
    "            tuple_param = self.get_f_fan_function_parameter_defaults(self.uncertainty_fan_function_type)\n",
    "\n",
    "        if len(tuple_param) == 4:\n",
    "            tp_0 = self.time_period_end_certainty\n",
    "            n = len(self.time_periods) - tp_0 - 1\n",
    "\n",
    "            return np.array([int(i > tp_0)*self.f_fan(i - tp_0 , n, *tuple_param) for i in range(len(self.time_periods))])\n",
    "        else:\n",
    "            raise ValueError(f\"Error: tuple_param {tuple_param} in build_ramp_vector has invalid length. It should have 4 parameters.\")\n",
    "\n",
    "    # basic function that determines the shape; based on a generalization of the sigmoid (includes linear option)\n",
    "    def f_fan(self, x, n, a, b, c, d):\n",
    "        \"\"\"\n",
    "         *defaults*\n",
    "        \n",
    "         for linear: \n",
    "            set a = 0, b = 2, c = 1, d = n/2 \n",
    "         for sigmoid:\n",
    "            set a = 1, b = 0, c = math.e, d = n/2\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        return (a*n + b*x)/(n*(1 + c**(d - x)))\n",
    "\n",
    "    # parameter defaults for the fan, based on the number of periods n\n",
    "    def get_f_fan_function_parameter_defaults(self, n: int, fan_type: str, return_type: str = \"params\"):\n",
    "        dict_ret = {\n",
    "            \"linear\": (0, 2, 1, n/2),\n",
    "            \"sigmoid\": (1, 0, math.e, n/2)\n",
    "        }\n",
    "\n",
    "        if return_type == \"params\":\n",
    "            return dict_ret[fan_type]\n",
    "        elif return_type == \"keys\":\n",
    "            return list(dict_ret.keys())\n",
    "        else:\n",
    "            str_avail_keys = \", \".join(list(dict_ret.keys()))\n",
    "            raise ValueError(f\"Error: invalid return_type '{return_type}'. Ensure it is one of the following: {str_avail_keys}.\")\n",
    "\n",
    "    # verify fan function parameters\n",
    "    def get_fan_function_parameters(self, fan_type):\n",
    "        \n",
    "        if type(fan_type) == str:\n",
    "            n = len(self.time_periods) - self.time_period_end_certainty\n",
    "            keys = self.get_f_fan_function_parameter_defaults(n, fan_type, \"keys\")\n",
    "            if fan_type in keys:\n",
    "                return self.get_f_fan_function_parameter_defaults(n, fan_type, \"params\")\n",
    "            else:\n",
    "                str_avail_keys = \", \".join(keys)\n",
    "                raise ValueError(f\"Error: no defaults specified for uncertainty fan function of type {fan_type}. Use a default or specify parameters a, b, c, and d. Default functional parameters are available for each of the following: {str_avail_keys}\")\n",
    "        elif type(fan_type) == tuple:\n",
    "            if len(fan_type) == 4:\n",
    "                if set([type(x) for x in fan_type]).issubset({int, float}):\n",
    "                    return fan_type\n",
    "                else:\n",
    "                    raise ValueError(f\"Error: fan parameter specification {fan_type} contains invalid parameters. Ensure they are numeric (int or float)\")\n",
    "            else:\n",
    "                raise ValueError(f\"Error: fan parameter specification {fan_type} invalid. 4 Parameters are required.\")\n",
    "            \n",
    "   \n",
    "\n",
    "    def build_futures(self, n_samples: int, random_seed: int):\n",
    "        print(f\"sampling {self.id_values}\")\n",
    "\n",
    "        \n",
    "    def generate_future(self, lhs_trial: float, lhs_trial_design: float = 1.0, constraints_mix_tg: tuple = (0, 1), baseline_future_q: bool = False):\n",
    "        \n",
    "        # index by variable_specification at keys\n",
    "        dict_out = {}\n",
    "        \n",
    "        if not self.variable_trajectory_group == None:\n",
    "            \n",
    "            #list(set([x[0] for x in self.ordered_trajectory_arrays.keys()]))\n",
    "            cat_mix = self.dict_required_tg_spec_fields[\"mixing_trajectory\"]\n",
    "            cat_b0 = self.dict_required_tg_spec_fields[\"trajectory_boundary_0\"]\n",
    "            cat_b1 = self.dict_required_tg_spec_fields[\"trajectory_boundary_1\"]\n",
    "\n",
    "            #if self.xl_type == \"x\":\n",
    "\n",
    "            # use mix between 0/1 (0 = 100% trajectory_boundary_0, 1 = 100% trajectory_boundary_1)\n",
    "            for vs in self.variable_specifications:\n",
    "                \n",
    "                dict_arrs = {\n",
    "                    cat_b0: self.ordered_trajectory_arrays[(vs, cat_b0)][\"data\"],\n",
    "                    cat_b1: self.ordered_trajectory_arrays[(vs, cat_b1)][\"data\"],\n",
    "                    cat_mix: self.ordered_trajectory_arrays[(vs, cat_mix)][\"data\"]\n",
    "                }\n",
    "\n",
    "\n",
    "                if (baseline_future_q):\n",
    "                    # for trajectory groups, the baseline is the specified mixing vector\n",
    "                    arr_out = self.mix_tensors(dict_arrs[cat_b0], dict_arrs[cat_b1], dict_arrs[cat_mix], constraints_mix_tg)\n",
    "                else:\n",
    "                    arr_out = self.mix_tensors(dict_arrs[cat_b0], dict_arrs[cat_b1], lhs_trial, constraints_mix_tg)\n",
    "\n",
    "                if self.xl_type == \"L\":\n",
    "                    \n",
    "                    if lhs_trial_design < 0:\n",
    "                        raise ValueError(f\"The value of lhs_trial_design = {lhs_trial_design} is invalid. lhs_trial_design must be >= 0.\")\n",
    "                    #\n",
    "                    # if the XL is an L, then we use the modified future as a base (reduce to include only baseline strategy), then add the uncertainty around the strategy effect\n",
    "                    #\n",
    "                    \n",
    "                    n_strat = len(self.dict_id_values[self.field_strategy_id])\n",
    "                    # get id coordinates( any of cat_mix, cat_b0, or cat_b1 would work -- use cat_mix)\n",
    "                    df_ids_ota = pd.concat([self.ordered_trajectory_arrays[(vs, cat_mix)][\"id_coordinates\"].copy().reset_index(drop = True), pd.DataFrame(arr_out, columns = self.fields_time_periods)], axis = 1)\n",
    "                    w = np.where(df_ids_ota[self.field_strategy_id] == self.dict_baseline_ids[self.field_strategy_id])\n",
    "                    df_ids_ota = df_ids_ota.iloc[w[0].repeat(n_strat)].reset_index(drop = True)\n",
    "                    arr_out = np.array(df_ids_ota[self.fields_time_periods])\n",
    "                    \n",
    "                    l_modified_cats = []\n",
    "                    inds0 = set(np.where(self.dict_strategy_info[\"baseline_strategy_data_table\"][self.field_var_spec] == vs)[0])\n",
    "                    \n",
    "                    for cat_cur in [cat_b0, cat_b1, cat_mix]:\n",
    "                        \n",
    "                        # get the index for the current vs/cat_cur\n",
    "                        inds = np.sort(np.array(list(inds0 & set(np.where(self.dict_strategy_info[\"baseline_strategy_data_table\"][self.field_trajgroup_spec] == cat_cur)[0]))))\n",
    "                        n_inds = len(inds)\n",
    "                        df_ids0 = self.dict_strategy_info[\"baseline_strategy_data_table\"][[x for x in self.fields_id if (x != self.field_strategy_id)]].loc[inds.repeat(n_strat)].reset_index(drop = True)\n",
    "                        new_strats = list(np.zeros(len(df_ids0)).astype(int))\n",
    "                        \n",
    "                        # initialize as list - we only do this to guarantee the sort is correct\n",
    "                        df_future_strat = np.zeros((n_inds*len(self.dict_id_values[self.field_strategy_id]), len(self.fields_time_periods)))\n",
    "                        ind_repl = 0\n",
    "                        \n",
    "                        ##  start loop\n",
    "                        for strat in self.dict_id_values[self.field_strategy_id]:\n",
    "\n",
    "                            # strategy ids\n",
    "                            new_strats[ind_repl*n_inds:((ind_repl + 1)*n_inds)] = [strat for x in inds]\n",
    "\n",
    "                            # get the strategy difference that is adjusted by lhs_trial_delta; if baseline strategy, use 0s\n",
    "                            df_repl = np.zeros((n_inds, len(self.fields_time_periods))) if (strat == self.dict_baseline_ids[self.field_strategy_id]) else self.dict_strategy_info[\"difference_arrays_by_strategy\"][strat][inds, :]*lhs_trial_design\n",
    "                            #df_repl = pd.concat([df_ids.reset_index(drop = True), pd.DataFrame(df_repl, columns = self.fields_time_periods)], axis = 1)\n",
    "                            #df_repl = pd.DataFrame(df_repl, columns = self.fields_time_periods)\n",
    "                            \n",
    "                            np.put(df_future_strat, range(n_inds*len(self.fields_time_periods)*ind_repl, n_inds*len(self.fields_time_periods)*(ind_repl + 1)), df_repl)\n",
    "                            \n",
    "                            #if init_q:\n",
    "                            #    df_future_strat = [df_repl for x in self.dict_id_values[self.field_strategy_id]]\n",
    "                            #    init_q = False\n",
    "                            #else:\n",
    "                            #    df_future_strat[ind_repl] = df_repl\n",
    "\n",
    "                            ind_repl += 1\n",
    "\n",
    "                        #df_future_strat = pd.concat(df_future_strat, axis = 0).reset_index(drop = True)\n",
    "                        df_ids0[self.field_strategy_id] = new_strats\n",
    "                        df_future_strat = pd.concat([df_ids0, pd.DataFrame(df_future_strat, columns = self.fields_time_periods)], axis = 1).sort_values(by = self.fields_id).reset_index(drop = True)\n",
    "                        l_modified_cats.append(dict_arrs[cat_cur] + np.array(df_future_strat[self.fields_time_periods]))\n",
    "                        \n",
    "                    arr_out = self.mix_tensors(*l_modified_cats, constraints_mix_tg)\n",
    "                    \n",
    "                    #\n",
    "                    # one option for this approach is to compare the difference between the \"L\" design uncertainty and the baseline and add this to the uncertain future (final array)\n",
    "                    #\n",
    "                    \n",
    "                dict_out.update({vs: arr_out})\n",
    "\n",
    "                \n",
    "        else:\n",
    "             \n",
    "            rv = self.uncertainty_ramp_vector\n",
    "            \n",
    "            for vs in self.variable_specifications:\n",
    "                # order the uniform scaling by the ordered trajectory arrays\n",
    "                vec_unif_scalar = self.ordered_by_ota_from_fid_dict(self.dict_variable_info[(vs, None)][\"uniform_scaling_q\"], (vs, None))\n",
    "                # gives 1s where we keep standard fanning (using the ramp vector) and 0s where we use uniform scaling \n",
    "                vec_base = 1 - vec_unif_scalar\n",
    "                \n",
    "                if max(vec_unif_scalar) > 0:\n",
    "                    vec_max_scalar = self.ordered_by_ota_from_fid_dict(self.dict_variable_info[(vs, None)][\"max_scalar\"], (vs, None))\n",
    "                    vec_min_scalar = self.ordered_by_ota_from_fid_dict(self.dict_variable_info[(vs, None)][\"min_scalar\"], (vs, None))\n",
    "                    vec_unif_scalar = vec_unif_scalar*(vec_min_scalar + lhs_trial*(vec_max_scalar - vec_min_scalar))\n",
    "                    \n",
    "                vec_unif_scalar = np.array([vec_unif_scalar]).transpose()\n",
    "                vec_base = np.array([vec_base]).transpose()\n",
    "                \n",
    "                delta_max = self.scalar_diff_arrays[(vs, None)][\"max_tp_end_delta\"]\n",
    "                delta_min = self.scalar_diff_arrays[(vs, None)][\"min_tp_end_delta\"]\n",
    "                delta_diff = delta_max - delta_min\n",
    "                delta_val = delta_min + lhs_trial*delta_diff\n",
    "\n",
    "                array_out = self.ordered_trajectory_arrays[(vs, None)][\"data\"] + (rv * np.array([delta_val]).transpose())\n",
    "                array_out = array_out*vec_base + vec_unif_scalar*self.ordered_trajectory_arrays[(vs, None)][\"data\"]\n",
    "                \n",
    "                dict_out.update({vs: array_out})\n",
    "\n",
    "        return dict_out\n",
    "\n",
    "var1 = 0\n",
    "#var1 = sampling_unit(df_tmp[df_tmp[\"variable_trajectory_group\"] == 6].rename(columns = {\"strategy_id\": \"estrategia_id\"}), {\"time_series_id\": 0, \"strategy_id\": 0}, 5, \"estrategia_id\")\n",
    "var1 = sampling_unit(df_tmp[df_tmp[\"variable_trajectory_group\"] == 9], {\"time_series_id\": 0, \"strategy_id\": 0}, 5)\n",
    "var2 = sampling_unit(df_tmp[df_tmp[\"variable_trajectory_group\"] == 18], {\"time_series_id\": 0, \"strategy_id\": 0}, 5)\n",
    "var3 = sampling_unit(df_tmp[df_tmp[\"variable\"] == \"manejo_holistico_de_gando\"], {\"time_series_id\": 0, \"strategy_id\": 0}, 5)\n",
    "var4 = sampling_unit(df_tmp[df_tmp[\"variable\"] == \"pib\"], {\"time_series_id\": 0, \"strategy_id\": 0}, 5, fan_function_specification = \"linear\")\n",
    "#var2 = sampling_unit(df_tmp[df_tmp[\"variable\"] == \"manejo_holistico_de_gando\"], {\"time_series_id\": 0}, 5)\n",
    "d1 = var3.dict_variable_info[(\"manejo_holistico_de_gando\", None)][\"max_scalar\"]#ordered_trajectory_arrays[(\"manejo_holistico_de_gando\", None)]\n",
    "#d1 = va\n",
    "#generate_future(.3)\n",
    "\n",
    "var3.scalar_diff_arrays[(\"manejo_holistico_de_gando\", None)]\n",
    "var3.uncertainty_ramp_vector\n",
    "var4.generate_future(1,  baseline_future_q = False)\n",
    "lhsv = pyd.lhs(4, 10000)\n",
    "\n",
    "t_0 = time.time()\n",
    "l_out = []\n",
    "for k in range(10000):\n",
    "    l_out.append(var3.generate_future(lhsv[k, 0],  baseline_future_q = False)[var3.variable_specifications[0]])\n",
    "    #var3.generate_future(lhsv[k, 0],  baseline_future_q = False)\n",
    "    \n",
    "t_delta = time.time() - t_0\n",
    "\n",
    "print(f\"10000 futures generated in {t_delta} seconds.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084],\n",
       "       [0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084, 0.94234084, 0.94234084, 0.94234084, 0.94234084,\n",
       "        0.94234084]])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var3.generate_future(lhsv[k, 0],  baseline_future_q = False)[var3.variable_specifications[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Agriculture': 'cat_agriculture',\n",
       " 'Forest': 'cat_forest',\n",
       " 'Land Use': 'cat_landuse',\n",
       " 'Livestock': 'cat_livestock',\n",
       " 'Liquid Waste': 'cat_waste_liquid',\n",
       " 'Solid Waste': 'cat_waste_solid',\n",
       " 'Other Energy: Stationary Emissions and Carbon Capture and Sequestration': 'cat_oesc',\n",
       " 'Industrial Energy': 'cat_industry',\n",
       " 'Transportation': 'cat_transportation',\n",
       " 'IPPU': 'cat_industry'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_attributes[\"abbreviation_subsector\"].field_maps[\"subsector_to_primary_category_py\"]#[\"cat_landuse\"].key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas</th>\n",
       "      <th>name</th>\n",
       "      <th>co_2_equivalent_factor</th>\n",
       "      <th>emission_gas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:math:`\\text{CH}_4`</td>\n",
       "      <td>Methane</td>\n",
       "      <td>27.9</td>\n",
       "      <td>ch4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:math:`\\text{CO}_2`</td>\n",
       "      <td>Carbon Dioxide</td>\n",
       "      <td>1.0</td>\n",
       "      <td>co2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HFC-23</td>\n",
       "      <td>HFC-23</td>\n",
       "      <td>14600.0</td>\n",
       "      <td>hfc23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HFC-32</td>\n",
       "      <td>HFC-32</td>\n",
       "      <td>771.0</td>\n",
       "      <td>hfc32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HFC-125</td>\n",
       "      <td>HFC-32</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>hfc125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HFC-134a</td>\n",
       "      <td>HFC-134a</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>hfc134a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HFC-143a</td>\n",
       "      <td>HFC-143a</td>\n",
       "      <td>5810.0</td>\n",
       "      <td>hfc143a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HFC-152</td>\n",
       "      <td>HFC-152</td>\n",
       "      <td>21.5</td>\n",
       "      <td>hfc152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HFC-152a</td>\n",
       "      <td>HFC-152a</td>\n",
       "      <td>164.0</td>\n",
       "      <td>hfc152a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>:math:`\\text{N}_2\\text{O}`</td>\n",
       "      <td>Nitrus Oxide</td>\n",
       "      <td>273.0</td>\n",
       "      <td>n2o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SF6</td>\n",
       "      <td>Sulfur Hexflouride</td>\n",
       "      <td>25200.0</td>\n",
       "      <td>sf6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            gas                 name  co_2_equivalent_factor  \\\n",
       "0          :math:`\\text{CH}_4`              Methane                     27.9   \n",
       "1          :math:`\\text{CO}_2`       Carbon Dioxide                      1.0   \n",
       "2                       HFC-23               HFC-23                  14600.0   \n",
       "3                       HFC-32               HFC-32                    771.0   \n",
       "4                      HFC-125               HFC-32                   3740.0   \n",
       "5                     HFC-134a             HFC-134a                   1530.0   \n",
       "6                     HFC-143a             HFC-143a                   5810.0   \n",
       "7                      HFC-152              HFC-152                     21.5   \n",
       "8                     HFC-152a             HFC-152a                    164.0   \n",
       "9   :math:`\\text{N}_2\\text{O}`         Nitrus Oxide                    273.0   \n",
       "10                         SF6   Sulfur Hexflouride                  25200.0   \n",
       "\n",
       "   emission_gas  \n",
       "0           ch4  \n",
       "1           co2  \n",
       "2         hfc23  \n",
       "3         hfc32  \n",
       "4        hfc125  \n",
       "5       hfc134a  \n",
       "6       hfc143a  \n",
       "7        hfc152  \n",
       "8       hfc152a  \n",
       "9           n2o  \n",
       "10          sf6  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.model_attributes.dict_attributes[\"emission_gas\"].table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['population_rural', 'population_urban', 'area_country_ha', 'occ_rate']"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_docs = os.path.join(os.path.dirname(os.getcwd()), \"docs\", \"source\")\n",
    "dir_attribute_tables = os.path.join(dir_docs, \"csvs\")\n",
    "fp_tab = os.path.join(dir_attribute_tables, \"attribute_cat_livestock.csv\")\n",
    "importlib.reload(sf)\n",
    "importlib.reload(ma)\n",
    "\n",
    "model_attributes = ma.ModelAttributes(dir_attribute_tables)\n",
    "\n",
    "#model_attributes.build_varlist_basic(x) for x in [\"Livestock\",]\n",
    "\n",
    "\n",
    "#vars_req_afolu = model_attributes.build_varlist(\"Agriculture\") + model_attributes.build_varlist(\"Forest\") + model_attributes.build_varlist(\"Livestock\") + model_attributes.build_varlist(\"Land Use\")\n",
    "model_attributes.build_varlist(\"General\")\n",
    "#+ model_attributes.build_varlist(\"Land Use\") + model_attributes.build_varlist(\"Livestock\")\n",
    "\n",
    "#model_attributes.get_subsector_attribute(\"Liquid Waste\", \"key_varreqs_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agrc': '``$CAT-AGRICULTURE$``',\n",
       " 'frst': '``$CAT-FOREST$``',\n",
       " 'lndu': '``$CAT-LANDUSE$``',\n",
       " 'lvst': '``$CAT-LIVESTOCK$``',\n",
       " 'wali': '``$CAT-WASTE-LIQUID$``',\n",
       " 'waso': '``$CAT-WASTE-SOLID$``',\n",
       " 'oesc': '``$CAT-OESC$``',\n",
       " 'elec': 'NONE',\n",
       " 'inen': '``$CAT-INDUSTRY$``',\n",
       " 'trns': '``$CAT-TRANSPORTATION$``',\n",
       " 'ippu': '``$CAT-INDUSTRY$``',\n",
       " 'econ': '``$CAT-ECONOMY``',\n",
       " 'gnrl': '``$CAT-GENERAL``'}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.model_attributes.dict_attributes[\"abbreviation_subsector\"].field_maps[\"abbreviation_subsector_to_primary_category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model_attributes.get_subsector_attribute(\"Agriculture\", \"key_varreqs_partial\")\n",
    "aa = [1, 2, 3]\n",
    "aa += [4, 5]\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Land Use Soil Carbon :math:\\\\text{CO}_2 Emission Factor': '``ef_soil_carbon_$CAT-LANDUSE$_$UNIT-MASS$_$EMISSION-GAS$_$UNIT-AREA$``  (``$UNIT-MASS$ = kg``, ``$EMISSION-GAS$ = co2``, ``$UNIT-AREA$ = ha``)', 'Land Use Pasture :math:\\\\text{N}_2\\\\text{O} Emission Factor': '``ef_existence_$CAT-LANDUSE$_$UNIT-MASS$_$EMISSION-GAS$_$UNIT-AREA$`` (``$UNIT-MASS$ = kg``, ``$EMISSION-GAS$ = n2o``, ``$UNIT-AREA$ = ha``)', 'Land Use BOC :math:\\\\text{CH}_4 Emission Factor': '``ef_boc_$CAT-LANDUSE$_$UNIT-MASS$_$EMISSION-GAS$_$UNIT-AREA$``  (``$UNIT-MASS$ = kg``, ``$EMISSION-GAS$ = ch4``, ``$UNIT-AREA$ = ha``)', 'Test variable': '``schema_$CAT-LANDUSE-I$_$CAT-LANDUSE-J$``'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-369-21acab261b92>:38: UserWarning: \tVariables 'Land Use BOC :math:\\text{CH}_4 Emission Factor', 'Land Use Pasture :math:\\text{N}_2\\text{O} Emission Factor', 'Land Use Soil Carbon :math:\\text{CO}_2 Emission Factor' not found in set_vars_to_cats_vars.\n",
      "  warnings.warn(f\"\\tVariables {l_drop} not found in set_vars_to_cats_vars.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['schema_wetlands_wetlands',\n",
       " 'schema_wetlands_grasslands',\n",
       " 'schema_grasslands_wetlands',\n",
       " 'schema_grasslands_grasslands']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def build_varlist_landuse(dict_vr_lndu_vvs, dict_vr_lndu_vvs, cat_lndu, attribute_land_use)\n",
    "subsector = \"Land Use\"\n",
    "# set some dicts\n",
    "dict_vr_vvs = model_attributes.dict_varreqs[model_attributes.get_subsector_attribute(subsector, \"key_varreqs_all\")].field_maps[\"variable_to_variable_schema\"]\n",
    "category = model_attributes.dict_attributes[\"abbreviation_subsector\"].field_maps[\"abbreviation_subsector_to_primary_category\"][model_attributes.get_subsector_attribute(subsector, \"abv_subsector\")].replace(\"`\", \"\")\n",
    "attribute_table = model_attributes.dict_attributes[model_attributes.get_subsector_attribute(subsector, \"pycategory_primary\")]\n",
    "# check for partial \n",
    "if model_attributes.get_subsector_attribute(subsector, \"key_varreqs_partial\") in model_attributes.dict_varreqs.keys():\n",
    "    aa = model_attributes.dict_varreqs[model_attributes.get_subsector_attribute(subsector, \"key_varreqs_partial\")].field_maps[\"variable_to_variable_schema\"]\n",
    "    print(aa)\n",
    "    \n",
    "# variables that are in the outer (Cartesian) product (i x j)\n",
    "dict_outer_vvs = model_attributes.dict_varreqs[model_attributes.get_subsector_attribute(subsector, \"key_varreqs_all\")].field_maps[\"variable_to_variable_schema\"]\n",
    "category_i = category.replace(\"$\", \"-I$\")[2:]\n",
    "category_j = category.replace(\"$\", \"-J$\")[2:]\n",
    "var_outer_prod = [x for x in dict_outer_vvs.keys() if (category_i in dict_outer_vvs[x]) and (category_j in dict_outer_vvs[x])]\n",
    "\n",
    "\n",
    "# initialize \n",
    "vars_out = build_var_basic(dict_vr_vvs, [x for x in dict_vr_vvs.keys() if (x not in var_outer_prod)], category, attribute_table.key_values)\n",
    "\n",
    "def build_var_outer(dict_vr_varschema, dict_vars_to_cats, category_to_replace, appendstr_i = \"-I\", appendstr_j = \"-J\"):\n",
    "    \n",
    "    cat_i = category_to_replace.replace(\"$\", f\"{appendstr_i}$\")[len(appendstr_i):]\n",
    "    cat_j = category_to_replace.replace(\"$\", f\"{appendstr_j}$\")[len(appendstr_j):]\n",
    "    \n",
    "    vars_out = []\n",
    "    \n",
    "    # run some checks and notify of any dropped variables \n",
    "    set_vr_schema_vars = set(dict_vr_varschema.keys())\n",
    "    set_vars_to_cats_vars = set(dict_vars_to_cats.keys())\n",
    "    vars_to_loop = set_vr_schema_vars & set_vars_to_cats_vars\n",
    "    \n",
    "    if len(set_vr_schema_vars - vars_to_loop) > 0:\n",
    "        l_drop = list(set_vr_schema_vars - vars_to_loop)\n",
    "        l_drop.sort()\n",
    "        l_drop = sf.format_print_list(l_drop)\n",
    "        warnings.warn(f\"\\tVariables {l_drop} not found in set_vars_to_cats_vars.\")\n",
    "    \n",
    "    if len(set_vars_to_cats_vars - vars_to_loop) > 0:\n",
    "        l_drop = list(set_vars_to_cats_vars - vars_to_loop)\n",
    "        l_drop.sort()\n",
    "        l_drop = sf.format_print_list(l_drop)\n",
    "        warnings.warn(f\"\\tVariables {l_drop} not found in set_vr_schema_vars.\")\n",
    "        \n",
    "    vars_to_loop = list(vars_to_loop)\n",
    "    \n",
    "    # loop over the variables available in both the variable schema dictionary and the dictionary mapping each variable to categories\n",
    "    for var in vars_to_loop:\n",
    "        var_schema = ma.clean_schema(dict_vr_varschema[var])\n",
    "        if (cat_i not in var_schema) or (cat_j not in var_schema):\n",
    "            fb_tab = dict_attributes[model_attributes.get_subsector_attribute(subsector, \"pycategory_primary\")].fp_table\n",
    "            raise ValueError(f\"Error in {var} variable schema: one of the outer categories '{cat_i}' or '{cat_j}' was not found. Check the attribute file found at '{fp_tab}'.\")\n",
    "        # fix the emission\n",
    "        for catval_i in dict_vars_to_cats[var]:\n",
    "            for catval_j in dict_vars_to_cats[var]:\n",
    "                vars_out.append(var_schema.replace(cat_i, catval_i).replace(cat_j, catval_j))\n",
    "                \n",
    "    return vars_out\n",
    "\n",
    "\n",
    "\n",
    "if model_attributes.get_subsector_attribute(subsector, \"key_varreqs_partial\") in model_attributes.dict_varreqs.keys():\n",
    "    dict_vr_vvs_partial = model_attributes.dict_varreqs[model_attributes.get_subsector_attribute(subsector, \"key_varreqs_partial\")].field_maps[\"variable_to_variable_schema\"]\n",
    "    dict_vr_vvs_cats = model_attributes.dict_varreqs[model_attributes.get_subsector_attribute(subsector, \"key_varreqs_partial\")].field_maps[\"variable_to_categories\"].copy()\n",
    "    category_i = category.replace(\"$\", \"-I$\")[2:]\n",
    "    category_j = category.replace(\"$\", \"-J$\")[2:]\n",
    "    vars_outer_prod = [x for x in dict_vr_vvs_partial.keys() if (category_i in dict_vr_vvs_partial[x]) and (category_j in dict_vr_vvs_partial[x])]\n",
    "    \n",
    "    \n",
    "    # split categories into list for use in build_var_outer\n",
    "    keys_loop = list(dict_vr_vvs_cats.keys())\n",
    "    for k in keys_loop:\n",
    "        if k in vars_outer_prod:\n",
    "            dict_vr_vvs_cats.update({k: dict_vr_vvs_cats[k].replace(\"`\", \"\").split(\"|\")})\n",
    "        else:\n",
    "            del dict_vr_vvs_cats[k]\n",
    "build_var_outer(dict_vr_vvs_partial, dict_vr_vvs_cats, category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Land Use Soil Carbon :math:\\\\text{CO}_2 Emission Factor': '``ef_soil_carbon_$CAT-LANDUSE$_$UNIT-MASS$_$EMISSION-GAS$_$UNIT-AREA$``  (``$UNIT-MASS$ = kg``, ``$EMISSION-GAS$ = co2``, ``$UNIT-AREA$ = ha``)',\n",
       " 'Land Use Pasture :math:\\\\text{N}_2\\\\text{O} Emission Factor': '``ef_existence_$CAT-LANDUSE$_$UNIT-MASS$_$EMISSION-GAS$_$UNIT-AREA$`` (``$UNIT-MASS$ = kg``, ``$EMISSION-GAS$ = n2o``, ``$UNIT-AREA$ = ha``)',\n",
       " 'Land Use BOC :math:\\\\text{CH}_4 Emission Factor': '``ef_boc_$CAT-LANDUSE$_$UNIT-MASS$_$EMISSION-GAS$_$UNIT-AREA$``  (``$UNIT-MASS$ = kg``, ``$EMISSION-GAS$ = ch4``, ``$UNIT-AREA$ = ha``)',\n",
       " 'Test variable': '``schema_$CAT-LANDUSE-I$_$CAT-LANDUSE-I$``'}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vr_vvs_partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat_landuse'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vr_vvs_partial\n",
    "dict_vr_vvs_cats\n",
    "model_attributes.get_subsector_attribute(subsector, \"pycategory_primary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frac_lu_initial_cropland',\n",
       " 'frac_lu_initial_forest_mangroves',\n",
       " 'frac_lu_initial_forest_primary',\n",
       " 'frac_lu_initial_forest_secondary',\n",
       " 'frac_lu_initial_grassland',\n",
       " 'frac_lu_initial_other',\n",
       " 'frac_lu_initial_settlements',\n",
       " 'frac_lu_initial_wetlands']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_var_basic(dict_vr_varschema, vars_to_loop, cat, cat_vals):\n",
    "    vars_out = []\n",
    "    # loop over required variables (exclude transition probability)\n",
    "    for var in vars_to_loop:\n",
    "        var_schema = ma.clean_schema(dict_vr_varschema[var])\n",
    "        # fix the emission\n",
    "        for catval in cat_vals:\n",
    "            vars_out.append(var_schema.replace(category, catval))\n",
    "    return vars_out\n",
    "            \n",
    "build_var_basic(dict_vr_vvs, [x for x in dict_vr_vvs.keys() if (x not in var_outer_prod)], category, attribute_table.key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_varreqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-7f71b11b5139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# build variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m vars_agrc = build_varlist_agriculture(\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mdict_varreqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category_af_agrc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"variable_to_variable_schema\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdict_attributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"abbreviation_subsector\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"abbreviation_subsector_to_primary_category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"agrc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdict_attributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cat_agriculture\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_varreqs' is not defined"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "###                                       ###\n",
    "###    BUILD VARIABLES FROM ATTRIBUTES    ###\n",
    "###                                       ###\n",
    "#############################################\n",
    "\n",
    "###############\n",
    "#    AFOLU    #\n",
    "###############\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "##  function build land use variables\n",
    "def build_varlist_landuse(dict_vr_lndu_vvs, dict_vr_lndu_vvs, cat_lndu, attribute_land_use)\n",
    "    vars_out = []\n",
    "    # loop over required variables\n",
    "    for var in dict_vr_lndu_vvs.keys():\n",
    "        var_schema = ma.clean_schema(dict_vr_vvs[var])\n",
    "        # fix the emission\n",
    "        for catval in attribute_table.key_values:\n",
    "            vars_out.append(var_schema.replace(category, catval))\n",
    "    return vars_out\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_varreqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-9a5dc99620c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_vr_lndu_vvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_varreqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category_af_lndu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"variable_to_variable_schema\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdict_vr_lndu_vvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_varreqs' is not defined"
     ]
    }
   ],
   "source": [
    "dict_vr_lndu_vvs = dict_varreqs[\"category_af_lndu\"].field_maps[\"variable_to_variable_schema\"]\n",
    "dict_vr_lndu_vvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$CAT-LANDUSE$\n",
      "$CAT-LANDUSE-J$\n",
      "$CAT-LANDUSE$\n",
      "$CAT-LANDUSE-J$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['frac_lu_cropland',\n",
       " 'frac_lu_forest',\n",
       " 'frac_lu_grassland',\n",
       " 'frac_lu_other',\n",
       " 'frac_lu_pasture',\n",
       " 'frac_lu_settlement',\n",
       " 'frac_lu_water',\n",
       " 'frac_lu_wetlands',\n",
       " 'pij_cropland_to_cropland',\n",
       " 'pij_cropland_to_forest',\n",
       " 'pij_cropland_to_grassland',\n",
       " 'pij_cropland_to_other',\n",
       " 'pij_cropland_to_pasture',\n",
       " 'pij_cropland_to_settlement',\n",
       " 'pij_cropland_to_water',\n",
       " 'pij_cropland_to_wetlands',\n",
       " 'pij_forest_to_cropland',\n",
       " 'pij_forest_to_forest',\n",
       " 'pij_forest_to_grassland',\n",
       " 'pij_forest_to_other',\n",
       " 'pij_forest_to_pasture',\n",
       " 'pij_forest_to_settlement',\n",
       " 'pij_forest_to_water',\n",
       " 'pij_forest_to_wetlands',\n",
       " 'pij_grassland_to_cropland',\n",
       " 'pij_grassland_to_forest',\n",
       " 'pij_grassland_to_grassland',\n",
       " 'pij_grassland_to_other',\n",
       " 'pij_grassland_to_pasture',\n",
       " 'pij_grassland_to_settlement',\n",
       " 'pij_grassland_to_water',\n",
       " 'pij_grassland_to_wetlands',\n",
       " 'pij_other_to_cropland',\n",
       " 'pij_other_to_forest',\n",
       " 'pij_other_to_grassland',\n",
       " 'pij_other_to_other',\n",
       " 'pij_other_to_pasture',\n",
       " 'pij_other_to_settlement',\n",
       " 'pij_other_to_water',\n",
       " 'pij_other_to_wetlands',\n",
       " 'pij_pasture_to_cropland',\n",
       " 'pij_pasture_to_forest',\n",
       " 'pij_pasture_to_grassland',\n",
       " 'pij_pasture_to_other',\n",
       " 'pij_pasture_to_pasture',\n",
       " 'pij_pasture_to_settlement',\n",
       " 'pij_pasture_to_water',\n",
       " 'pij_pasture_to_wetlands',\n",
       " 'pij_settlement_to_cropland',\n",
       " 'pij_settlement_to_forest',\n",
       " 'pij_settlement_to_grassland',\n",
       " 'pij_settlement_to_other',\n",
       " 'pij_settlement_to_pasture',\n",
       " 'pij_settlement_to_settlement',\n",
       " 'pij_settlement_to_water',\n",
       " 'pij_settlement_to_wetlands',\n",
       " 'pij_water_to_cropland',\n",
       " 'pij_water_to_forest',\n",
       " 'pij_water_to_grassland',\n",
       " 'pij_water_to_other',\n",
       " 'pij_water_to_pasture',\n",
       " 'pij_water_to_settlement',\n",
       " 'pij_water_to_water',\n",
       " 'pij_water_to_wetlands',\n",
       " 'pij_wetlands_to_cropland',\n",
       " 'pij_wetlands_to_forest',\n",
       " 'pij_wetlands_to_grassland',\n",
       " 'pij_wetlands_to_other',\n",
       " 'pij_wetlands_to_pasture',\n",
       " 'pij_wetlands_to_settlement',\n",
       " 'pij_wetlands_to_water',\n",
       " 'pij_wetlands_to_wetlands',\n",
       " 'ef_luconversion_cropland_to_cropland',\n",
       " 'ef_luconversion_cropland_to_forest',\n",
       " 'ef_luconversion_cropland_to_grassland',\n",
       " 'ef_luconversion_cropland_to_other',\n",
       " 'ef_luconversion_cropland_to_pasture',\n",
       " 'ef_luconversion_cropland_to_settlement',\n",
       " 'ef_luconversion_cropland_to_water',\n",
       " 'ef_luconversion_cropland_to_wetlands',\n",
       " 'ef_luconversion_forest_to_cropland',\n",
       " 'ef_luconversion_forest_to_forest',\n",
       " 'ef_luconversion_forest_to_grassland',\n",
       " 'ef_luconversion_forest_to_other',\n",
       " 'ef_luconversion_forest_to_pasture',\n",
       " 'ef_luconversion_forest_to_settlement',\n",
       " 'ef_luconversion_forest_to_water',\n",
       " 'ef_luconversion_forest_to_wetlands',\n",
       " 'ef_luconversion_grassland_to_cropland',\n",
       " 'ef_luconversion_grassland_to_forest',\n",
       " 'ef_luconversion_grassland_to_grassland',\n",
       " 'ef_luconversion_grassland_to_other',\n",
       " 'ef_luconversion_grassland_to_pasture',\n",
       " 'ef_luconversion_grassland_to_settlement',\n",
       " 'ef_luconversion_grassland_to_water',\n",
       " 'ef_luconversion_grassland_to_wetlands',\n",
       " 'ef_luconversion_other_to_cropland',\n",
       " 'ef_luconversion_other_to_forest',\n",
       " 'ef_luconversion_other_to_grassland',\n",
       " 'ef_luconversion_other_to_other',\n",
       " 'ef_luconversion_other_to_pasture',\n",
       " 'ef_luconversion_other_to_settlement',\n",
       " 'ef_luconversion_other_to_water',\n",
       " 'ef_luconversion_other_to_wetlands',\n",
       " 'ef_luconversion_pasture_to_cropland',\n",
       " 'ef_luconversion_pasture_to_forest',\n",
       " 'ef_luconversion_pasture_to_grassland',\n",
       " 'ef_luconversion_pasture_to_other',\n",
       " 'ef_luconversion_pasture_to_pasture',\n",
       " 'ef_luconversion_pasture_to_settlement',\n",
       " 'ef_luconversion_pasture_to_water',\n",
       " 'ef_luconversion_pasture_to_wetlands',\n",
       " 'ef_luconversion_settlement_to_cropland',\n",
       " 'ef_luconversion_settlement_to_forest',\n",
       " 'ef_luconversion_settlement_to_grassland',\n",
       " 'ef_luconversion_settlement_to_other',\n",
       " 'ef_luconversion_settlement_to_pasture',\n",
       " 'ef_luconversion_settlement_to_settlement',\n",
       " 'ef_luconversion_settlement_to_water',\n",
       " 'ef_luconversion_settlement_to_wetlands',\n",
       " 'ef_luconversion_water_to_cropland',\n",
       " 'ef_luconversion_water_to_forest',\n",
       " 'ef_luconversion_water_to_grassland',\n",
       " 'ef_luconversion_water_to_other',\n",
       " 'ef_luconversion_water_to_pasture',\n",
       " 'ef_luconversion_water_to_settlement',\n",
       " 'ef_luconversion_water_to_water',\n",
       " 'ef_luconversion_water_to_wetlands',\n",
       " 'ef_luconversion_wetlands_to_cropland',\n",
       " 'ef_luconversion_wetlands_to_forest',\n",
       " 'ef_luconversion_wetlands_to_grassland',\n",
       " 'ef_luconversion_wetlands_to_other',\n",
       " 'ef_luconversion_wetlands_to_pasture',\n",
       " 'ef_luconversion_wetlands_to_settlement',\n",
       " 'ef_luconversion_wetlands_to_water',\n",
       " 'ef_luconversion_wetlands_to_wetlands']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# landuse, agriculture, livestock, forest\n",
    "# abbreviation_subsector\n",
    "def build_varlist_landuse(dict_vr_lndu_vvs, cat_lndu, attribute_land_use):\n",
    "    vars_out = []\n",
    "    # variables that are in the outer (Cartesian) product (i x j)\n",
    "    var_outer_prod = [\n",
    "        \"Unadjusted Land Use Transition Probability\",\n",
    "        \":math:\\\\text{CO}_2 Land Use Conversion Emission Factor\"\n",
    "    ]\n",
    "    \n",
    "    # loop over required variables (exclude transition probability)\n",
    "    for var in [x for x in dict_vr_lndu_vvs.keys() if (x not in var_outer_prod)]:\n",
    "        var_schema = ma.clean_schema(dict_vr_lndu_vvs[var])\n",
    "        # fix the emission\n",
    "        for catval in attribute_land_use.key_values:\n",
    "            vars_out.append(var_schema.replace(cat_lndu, catval))\n",
    "    \n",
    "    ##  set variables that associated with the transition matrix\n",
    "    cat_lndu_i = cat_lndu.replace(\"$\", \"-I$\")[2:]\n",
    "    cat_lndu_j = cat_lndu.replace(\"$\", \"-J$\")[2:]\n",
    "    for var in var_outer_prod:\n",
    "        var_schema = ma.clean_schema(dict_vr_lndu_vvs[var])\n",
    "        if (cat_lndu_i not in var_schema) or (cat_lndu_j not in var_schema):\n",
    "            fb_tab = dict_attributes[\"cat_landuse\"].fp_table\n",
    "            raise ValueError(f\"Error in {var} variable schema: one of the outer categories '{cat_lndu_j}' or '{cat_lndu_j}' was not found. Check the attribute file found at '{fp_tab}'.\")\n",
    "        print(cat_lndu)\n",
    "        print(cat_lndu_j)\n",
    "        # fix the emission\n",
    "        for catval_i in attribute_land_use.key_values:\n",
    "            for catval_j in attribute_land_use.key_values:\n",
    "                vars_out.append(var_schema.replace(cat_lndu_i, catval_i).replace(cat_lndu_j, catval_j))\n",
    "        \n",
    "    return vars_out\n",
    "\n",
    "build_varlist_landuse(\n",
    "    dict_varreqs[\"category_af_lndu\"].field_maps[\"variable_to_variable_schema\"], \n",
    "    dict_attributes[\"abbreviation_subsector\"].field_maps[\"abbreviation_subsector_to_primary_category\"][\"lndu\"].replace(\"`\", \"\"),\n",
    "    dict_attributes[\"cat_landuse\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pij_$CAT-LANDUSE-I$_$CAT-LANDUSE-J$'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_transition_probability = \"Unadjusted Land Use Transition Probability\"\n",
    "var_schema = ma.clean_schema(dict_vr_lndu_vvs[var_transition_probability])\n",
    "var_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jsyme/Documents/Projects/git_jbus/lac_decarbonization/docs/source/csvs/attribute_cat_land_use.csv'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_attributes[\"cat_landuse\"].fp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_gas</th>\n",
       "      <th>name</th>\n",
       "      <th>:math:\\text{co}_2_equivalent_factor</th>\n",
       "      <th>emission_gas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:math:`\\text{CH}_4`</td>\n",
       "      <td>Methane</td>\n",
       "      <td>27.9</td>\n",
       "      <td>ch4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:math:`\\text{CO}_2`</td>\n",
       "      <td>Carbon Dioxide</td>\n",
       "      <td>1.0</td>\n",
       "      <td>co2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HFC-23</td>\n",
       "      <td>HFC-23</td>\n",
       "      <td>14600.0</td>\n",
       "      <td>hfc23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HFC-32</td>\n",
       "      <td>HFC-32</td>\n",
       "      <td>771.0</td>\n",
       "      <td>hfc32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HFC-125</td>\n",
       "      <td>HFC-32</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>hfc125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HFC-134a</td>\n",
       "      <td>HFC-134a</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>hfc134a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HFC-143a</td>\n",
       "      <td>HFC-143a</td>\n",
       "      <td>5810.0</td>\n",
       "      <td>hfc143a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HFC-152</td>\n",
       "      <td>HFC-152</td>\n",
       "      <td>21.5</td>\n",
       "      <td>hfc152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HFC-152a</td>\n",
       "      <td>HFC-152a</td>\n",
       "      <td>164.0</td>\n",
       "      <td>hfc152a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>:math:`\\text{N}_2\\text{O}`</td>\n",
       "      <td>Nitrus Oxide</td>\n",
       "      <td>273.0</td>\n",
       "      <td>n2o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SF6</td>\n",
       "      <td>Sulfur Hexflouride</td>\n",
       "      <td>25200.0</td>\n",
       "      <td>sf6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _gas                 name  \\\n",
       "0          :math:`\\text{CH}_4`              Methane    \n",
       "1          :math:`\\text{CO}_2`       Carbon Dioxide    \n",
       "2                       HFC-23               HFC-23    \n",
       "3                       HFC-32               HFC-32    \n",
       "4                      HFC-125               HFC-32    \n",
       "5                     HFC-134a             HFC-134a    \n",
       "6                     HFC-143a             HFC-143a    \n",
       "7                      HFC-152              HFC-152    \n",
       "8                     HFC-152a             HFC-152a    \n",
       "9   :math:`\\text{N}_2\\text{O}`         Nitrus Oxide    \n",
       "10                         SF6   Sulfur Hexflouride    \n",
       "\n",
       "    :math:\\text{co}_2_equivalent_factor emission_gas  \n",
       "0                                  27.9          ch4  \n",
       "1                                   1.0          co2  \n",
       "2                               14600.0        hfc23  \n",
       "3                                 771.0        hfc32  \n",
       "4                                3740.0       hfc125  \n",
       "5                                1530.0      hfc134a  \n",
       "6                                5810.0      hfc143a  \n",
       "7                                  21.5       hfc152  \n",
       "8                                 164.0      hfc152a  \n",
       "9                                 273.0          n2o  \n",
       "10                              25200.0          sf6  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dict_attributes[\"emission_gas\"].table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1859851  5.72533703 4.80996349 4.60127075 4.73050372 4.83060487\n",
      "  4.859114   4.21079673 4.10882331 5.04782476]\n",
      " [4.16060803 5.40830293 4.5998736  5.5224147  4.78710845 5.11692437\n",
      "  5.87251584 5.27479694 4.88184604 5.49888557]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "\n",
      "****************************************\n",
      "\n",
      "[[5.1859851  5.72533703 4.80996349 4.60127075 4.73050372 4.83060487\n",
      "  4.859114   4.21079673 4.10882331 5.04782476]\n",
      " [4.16060803 5.40830293 4.5998736  5.5224147  4.78710845 5.11692437\n",
      "  5.87251584 5.27479694 4.88184604 5.49888557]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[5.1859851  5.72533703 4.80996349 4.60127075 4.73050372 4.83060487\n",
      "  4.859114   4.21079673 4.10882331 5.04782476]\n",
      " [4.16060803 5.40830293 4.5998736  5.5224147  4.78710845 5.11692437\n",
      "  5.87251584 5.27479694 4.88184604 5.49888557]\n",
      " [8.         8.         8.         8.         8.         8.\n",
      "  8.         8.         8.         8.        ]\n",
      " [8.         8.         8.         8.         8.         8.\n",
      "  8.         8.         8.         8.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "\n",
      "****************************************\n",
      "\n",
      "[[8. 8. 8. 8. 8. 8. 8. 8. 8. 8.]\n",
      " [8. 8. 8. 8. 8. 8. 8. 8. 8. 8.]]\n"
     ]
    }
   ],
   "source": [
    "aa = np.zeros((6, 10))\n",
    "aa1 = np.random.rand(2, 10)*2+4\n",
    "aa2 = np.ones((2, 10))*8\n",
    "\n",
    "np.put(aa, range(20), aa1)\n",
    "print(aa)\n",
    "print(\"\\n\" + \"**\"*20 + \"\\n\")\n",
    "print(aa1)\n",
    "print(\"\\n\"*4)\n",
    "np.put(aa, range(20, 40), aa2)\n",
    "print(aa)\n",
    "print(\"\\n\" + \"**\"*20 + \"\\n\")\n",
    "print(aa2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>time_series_id</th>\n",
       "      <th>strategy_id</th>\n",
       "      <th>type</th>\n",
       "      <th>variable</th>\n",
       "      <th>normalize_group</th>\n",
       "      <th>trajgroup_no_vary_q</th>\n",
       "      <th>uniform_scaling_q</th>\n",
       "      <th>min_35</th>\n",
       "      <th>max_35</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>variable_trajectory_group</th>\n",
       "      <th>variable_trajectory_group_trajectory_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9384</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_hydrogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9385</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_hydrogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05625</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.06875</td>\n",
       "      <td>0.07500</td>\n",
       "      <td>0.08125</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_kerosene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_kerosene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94375</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.93125</td>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.91875</td>\n",
       "      <td>0.91250</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9408</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_hydrogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9409</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_hydrogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9420</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_kerosene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9421</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_kerosene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>trajectory_boundary_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9432</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_hydrogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>9</td>\n",
       "      <td>mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_hydrogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9444</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_kerosene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>9</td>\n",
       "      <td>mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>transport</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>incertidumbre</td>\n",
       "      <td>transport_frac_aviation_kerosene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9</td>\n",
       "      <td>mix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sector  time_series_id  strategy_id           type  \\\n",
       "9384  transport               0            0  incertidumbre   \n",
       "9385  transport               0            1  incertidumbre   \n",
       "9396  transport               0            0  incertidumbre   \n",
       "9397  transport               0            1  incertidumbre   \n",
       "9408  transport               0            0  incertidumbre   \n",
       "9409  transport               0            1  incertidumbre   \n",
       "9420  transport               0            0  incertidumbre   \n",
       "9421  transport               0            1  incertidumbre   \n",
       "9432  transport               0            0  incertidumbre   \n",
       "9433  transport               0            1  incertidumbre   \n",
       "9444  transport               0            0  incertidumbre   \n",
       "9445  transport               0            1  incertidumbre   \n",
       "\n",
       "                              variable  normalize_group  trajgroup_no_vary_q  \\\n",
       "9384  transport_frac_aviation_hydrogen              NaN                  NaN   \n",
       "9385  transport_frac_aviation_hydrogen              NaN                  NaN   \n",
       "9396  transport_frac_aviation_kerosene              NaN                  NaN   \n",
       "9397  transport_frac_aviation_kerosene              NaN                  NaN   \n",
       "9408  transport_frac_aviation_hydrogen              NaN                  NaN   \n",
       "9409  transport_frac_aviation_hydrogen              NaN                  NaN   \n",
       "9420  transport_frac_aviation_kerosene              NaN                  NaN   \n",
       "9421  transport_frac_aviation_kerosene              NaN                  NaN   \n",
       "9432  transport_frac_aviation_hydrogen              NaN                  NaN   \n",
       "9433  transport_frac_aviation_hydrogen              NaN                  NaN   \n",
       "9444  transport_frac_aviation_kerosene              NaN                  NaN   \n",
       "9445  transport_frac_aviation_kerosene              NaN                  NaN   \n",
       "\n",
       "      uniform_scaling_q  min_35  max_35  ...       28       29       30  \\\n",
       "9384                NaN     1.0     1.0  ...  0.00000  0.00000  0.00000   \n",
       "9385                NaN     1.0     1.0  ...  0.05625  0.06250  0.06875   \n",
       "9396                NaN     1.0     1.0  ...  1.00000  1.00000  1.00000   \n",
       "9397                NaN     1.0     1.0  ...  0.94375  0.93750  0.93125   \n",
       "9408                NaN     1.0     1.0  ...  0.00000  0.00000  0.00000   \n",
       "9409                NaN     1.0     1.0  ...  0.00000  0.00000  0.00000   \n",
       "9420                NaN     1.0     1.0  ...  1.00000  1.00000  1.00000   \n",
       "9421                NaN     1.0     1.0  ...  1.00000  1.00000  1.00000   \n",
       "9432                1.0     1.0     1.0  ...  0.00001  0.00001  0.00001   \n",
       "9433                1.0     1.0     1.0  ...  1.00000  1.00000  1.00000   \n",
       "9444                1.0     1.0     1.0  ...  0.00001  0.00001  0.00001   \n",
       "9445                1.0     1.0     1.0  ...  1.00000  1.00000  1.00000   \n",
       "\n",
       "           31       32       33       34       35  variable_trajectory_group  \\\n",
       "9384  0.00000  0.00000  0.00000  0.00000  0.00000                          9   \n",
       "9385  0.07500  0.08125  0.08750  0.09375  0.10000                          9   \n",
       "9396  1.00000  1.00000  1.00000  1.00000  1.00000                          9   \n",
       "9397  0.92500  0.91875  0.91250  0.90625  0.90000                          9   \n",
       "9408  0.00000  0.00000  0.00000  0.00000  0.00000                          9   \n",
       "9409  0.00000  0.00000  0.00000  0.00000  0.00000                          9   \n",
       "9420  1.00000  1.00000  1.00000  1.00000  1.00000                          9   \n",
       "9421  1.00000  1.00000  1.00000  1.00000  1.00000                          9   \n",
       "9432  0.00001  0.00001  0.00001  0.00001  0.00001                          9   \n",
       "9433  1.00000  1.00000  1.00000  1.00000  1.00000                          9   \n",
       "9444  0.00001  0.00001  0.00001  0.00001  0.00001                          9   \n",
       "9445  1.00000  1.00000  1.00000  1.00000  1.00000                          9   \n",
       "\n",
       "      variable_trajectory_group_trajectory_type  \n",
       "9384                      trajectory_boundary_1  \n",
       "9385                      trajectory_boundary_1  \n",
       "9396                      trajectory_boundary_1  \n",
       "9397                      trajectory_boundary_1  \n",
       "9408                      trajectory_boundary_0  \n",
       "9409                      trajectory_boundary_0  \n",
       "9420                      trajectory_boundary_0  \n",
       "9421                      trajectory_boundary_0  \n",
       "9432                                        mix  \n",
       "9433                                        mix  \n",
       "9444                                        mix  \n",
       "9445                                        mix  \n",
       "\n",
       "[12 rows x 48 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp[\n",
    "    (\n",
    "        df_tmp[\"variable_trajectory_group\"] == 9\n",
    "    ) & (\n",
    "        df_tmp[\"strategy_id\"].isin([0, 1])\n",
    "    )  & (\n",
    "        df_tmp[\"time_series_id\"].isin([0])\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.84910798072815\n"
     ]
    }
   ],
   "source": [
    "#### t_0 = time.time()\n",
    "l_out = []\n",
    "t_0 = time.time()\n",
    "for k in range(1000):\n",
    "    #l_out.append(var1.generate_future(lhsv[k, 0], lhs_trial_design = lhsv[k, 1], baseline_future_q = False)[var1.variable_specifications[0]])\n",
    "    ab = var1.generate_future(lhsv[k, 0], lhs_trial_design = 0, baseline_future_q = False)\n",
    "    #print(np.array([ab[x][:, 35] for x in ab.keys()]).transpose())\n",
    "t_delta = time.time() - t_0\n",
    "print(t_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transport_frac_aviation_hydrogen': array([[0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.009375, 0.01875 , 0.028125, 0.0375  ,\n",
       "         0.046875, 0.05625 , 0.065625, 0.075   , 0.084375, 0.09375 ,\n",
       "         0.103125, 0.1125  , 0.121875, 0.13125 , 0.140625, 0.15    ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.009375, 0.01875 , 0.028125, 0.0375  ,\n",
       "         0.046875, 0.05625 , 0.065625, 0.075   , 0.084375, 0.09375 ,\n",
       "         0.103125, 0.1125  , 0.121875, 0.13125 , 0.140625, 0.15    ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.      , 0.      ]]),\n",
       " 'transport_frac_aviation_kerosene': array([[1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 0.990625, 0.98125 , 0.971875, 0.9625  ,\n",
       "         0.953125, 0.94375 , 0.934375, 0.925   , 0.915625, 0.90625 ,\n",
       "         0.896875, 0.8875  , 0.878125, 0.86875 , 0.859375, 0.85    ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 0.990625, 0.98125 , 0.971875, 0.9625  ,\n",
       "         0.953125, 0.94375 , 0.934375, 0.925   , 0.915625, 0.90625 ,\n",
       "         0.896875, 0.8875  , 0.878125, 0.86875 , 0.859375, 0.85    ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ],\n",
       "        [1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ,\n",
       "         1.      , 1.      , 1.      , 1.      , 1.      , 1.      ]])}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1.generate_future(0.1, lhs_trial_design = 0.5, baseline_future_q = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cat_mix = var1.dict_required_tg_spec_fields[\"mixing_trajectory\"]\n",
    "cat_b0 = var1.dict_required_tg_spec_fields[\"trajectory_boundary_0\"]\n",
    "cat_b1 = var1.dict_required_tg_spec_fields[\"trajectory_boundary_1\"]\n",
    "vs = \"steel_heat_biomass\"\n",
    "cat_cur = cat_mix\n",
    "\n",
    "ind_repl = 0\n",
    "strat = 1\n",
    "lhs_trial_delta = 0.6\n",
    "\n",
    "\n",
    "#\n",
    "# initialize some attributes\n",
    "#    field_trajgroup = \"variable_trajectory_group\"\n",
    "#    field_trajgroup_spec = \"variable_trajectory_group_trajectory_type\"\n",
    "#    field_uniform_scaling_q = \"uniform_scaling_q\"\n",
    "#    field_var_spec = \"variable\"\n",
    "\n",
    "var1.ordered_trajectory_arrays[(\"steel_heat_biomass\", \"mix\")][\"id_coordinates\"]\n",
    "var1.dict_strategy_info.keys()\n",
    "#var1.dict_strategy_info[\"baseline_strategy_data_table\"][\n",
    "\n",
    "# get the index for the current vs/cat_cur\n",
    "inds = np.where(var1.dict_strategy_info[\"baseline_strategy_data_table\"][var1.field_var_spec].isin([vs]) & var1.dict_strategy_info[\"baseline_strategy_data_table\"][var1.field_trajgroup_spec].isin([cat_cur]))\n",
    "df_ids0 = var1.dict_strategy_info[\"baseline_strategy_data_table\"][[x for x in var1.fields_id if (x != var1.field_strategy_id)]].loc[inds]\n",
    "\n",
    "# initialize as list - we only do this to guarantee the sort is correct\n",
    "df_future_strat = []\n",
    "##  start loop\n",
    "for strat in var1.dict_id_values[var1.field_strategy_id]:\n",
    "\n",
    "    # get ids for sort\n",
    "    df_ids = df_ids0.copy()\n",
    "    df_ids[var1.field_strategy_id] = strat\n",
    "    \n",
    "    # get the strategy difference that is adjusted by lhs_trial_delta; if baseline strategy, use 0s\n",
    "    df_repl = np.zeros((len(inds[0]), len(var1.fields_time_periods))) if (strat == var1.dict_baseline_ids[var1.field_strategy_id]) else var1.dict_strategy_info[\"difference_arrays_by_strategy\"][strat][inds[0], :]*lhs_trial_delta\n",
    "    df_repl = pd.concat([df_ids.reset_index(drop = True), pd.DataFrame(df_repl, columns = var1.fields_time_periods)], axis = 1 )\n",
    "    df_future_strat.append(df_repl)\n",
    "\n",
    "df_future_strat = pd.concat(df_future_strat, axis = 0).sort_values(by = var1.fields_id).reset_index(drop = True)\n",
    "arr_out[vs] + np.array(df_future_strat[var1.fields_time_periods]\n",
    "#pd.concat([df_future_strat[var1.fields_id], pd.DataFrame(arr_out[vs] + np.array(df_future_strat[var1.fields_time_periods]), columns = var1.fields_time_periods)], axis = 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((len(inds[0]), len(var1.fields_time_periods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tmp[~df_tmp[\"variable_trajectory_group\"].isna() & (~df_tmp[\"variable_trajectory_group_trajectory_type\"].isna())]#.head()\n",
    "#str(df_tmp[\"variable_trajectory_group\"].iloc[9]) == \"<NA>\"\n",
    "#[[\"trajgroup_1\" in x for x in df_tmp0[\"parameter\"]]][\"parameter\"].unique()\n",
    "#df_tmp[df_tmp[\"variable_trajectory_group\"].isin([10])]\n",
    "#df_tmp0[[\"pib\" in x for x in df_tmp0[\"parameter\"]]]#[\"parameter\"]\n",
    "var1.dict_strategy_info[\"difference_arrays_by_strategy\"][1]#.keys()\n",
    "lhs_trial_design = 0.6\n",
    "lhs_trial = 0.5\n",
    "baseline_future_q = False\n",
    "\n",
    "arr_0 = np.zeros(var1.ordered_trajectory_arrays[(var1.variable_specifications[0], \"mix\")][\"data\"].shape)\n",
    "ind = 0\n",
    "\n",
    "cat_mix = var1.dict_required_tg_spec_fields[\"mixing_trajectory\"]\n",
    "cat_b0 = var1.dict_required_tg_spec_fields[\"trajectory_boundary_0\"]\n",
    "cat_b1 = var1.dict_required_tg_spec_fields[\"trajectory_boundary_1\"]\n",
    "\n",
    "for strat in var1.dict_id_values[var1.field_strategy_id]:\n",
    "    \n",
    "    # create a new dataframe, add the strategy id, then add in additional columns like variable, type etc.\n",
    "    df_tmp = pd.DataFrame(var1.dict_strategy_info[\"baseline_strategy_array\"] + lhs_trial_design * var1.dict_strategy_info[\"difference_arrays_by_strategy\"][strat], columns = var1.fields_time_periods)\n",
    "    df_tmp[var1.field_strategy_id] = strat\n",
    "    df_tmp = sf.df_get_missing_fields_from_source_df(df_tmp, var1.dict_strategy_info[\"baseline_strategy_data_table\"])\n",
    "    \n",
    "    #use the ordered trajectory arrays fuction\n",
    "    dict_ota_tmp = var1.get_ordered_trajectory_arrays(df_tmp2, var1.fields_id, var1.fields_time_periods, var1.variable_specifications);\n",
    "\n",
    "    # use mix between 0/1 (0 = 100% trajectory_boundary_0, 1 = 100% trajectory_boundary_1)\n",
    "    for vs in var1.variable_specifications:\n",
    "        arr_b0 = dict_ota_tmp[(vs, cat_b0)][\"data\"]\n",
    "        arr_b1 = dict_ota_tmp[(vs, cat_b1)][\"data\"]\n",
    "        arr_mix = dict_ota_tmp[(vs, cat_mix)][\"data\"]\n",
    "\n",
    "        if baseline_future_q:\n",
    "            # for trajectory groups, the baseline is the specified mixing vector\n",
    "            arr_out = self.mix_tensors(arr_b0, arr_b1, arr_mix, constraints_mix_tg)\n",
    "        else:\n",
    "            arr_out = self.mix_tensors(arr_b0, arr_b1, lhs_trial, constraints_mix_tg)\n",
    "    \n",
    "    \n",
    "    \n",
    "#df_tmp = pd.concat([df_tmp, ])\n",
    "\n",
    "#var1.ordered_trajectory_arrays\n",
    "\n",
    "#var1.get_ordered_trajectory_arrays(self.data_table, self.fields_id, self.fields_time_periods, self.variable_specifications)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[(df_tmp[\"variable_trajectory_group\"] == 8) & (df_tmp[\"variable\"] == \"steel_heat_coal\")];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'manejo_holistico_de_gando': array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "        [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "         0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]])}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#var1.generate_future(0, baseline_future_q = False)\n",
    "var3.generate_future(0, baseline_future_q = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### var3.dict_strategy_info[\"baseline_strategy_data_table\"]\n",
    "#var4.dict_variable_info[(\"pib\", \"mix\")][\"max_scalar\"]#ordered_trajectory_arrays[(\"manejo_holistico_de_gando\", None)][\"data\"][:,-1]\n",
    "#[tuple(x) for x in np.array(var4.ordered_trajectory_arrays[(\"pib\", \"mix\")][\"id_coordinates\"])]\n",
    "#var4.ordered_trajectory_arrays[(\"pib\", \"mix\")][\"data\"][:, -5:]\n",
    "y = var4.build_ramp_vector((0, 2, 1, len(var4.time_periods) - var4.time_period_end_certainty))\n",
    "#y = var4.build_ramp_vector((1, 0, math.e, (len(var4.time_periods) - var4.time_period_end_certainty)/2))\n",
    "x = var4.time_periods\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'manejo_holistico_de_gando': array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
       "        [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "         0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]])}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var3.ordered_trajectory_arrays[(\"manejo_holistico_de_gando\", None)]#()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1, -2],\n",
       "       [-1, -2,  0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#var4.dict_variable_info[(vs, tgs)][\"uniform_scaling_q\"]\n",
    "#var3.dict_variable_info[(\"manejo_holistico_de_gando\", None)]#[\"uniform_scaling_q\"]\n",
    "1 - np.array([[1, 2, 3], [2, 3, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " {'baseline_strategy_data_table':                                  variable  \\\n",
       "  8      residential_apartment_acs_electric   \n",
       "  4      residential_apartment_acs_electric   \n",
       "  0      residential_apartment_acs_electric   \n",
       "  9   residential_apartment_acs_natural_gas   \n",
       "  5   residential_apartment_acs_natural_gas   \n",
       "  1   residential_apartment_acs_natural_gas   \n",
       "  10      residential_apartment_acs_pliqgas   \n",
       "  6       residential_apartment_acs_pliqgas   \n",
       "  2       residential_apartment_acs_pliqgas   \n",
       "  11        residential_apartment_acs_solar   \n",
       "  7         residential_apartment_acs_solar   \n",
       "  3         residential_apartment_acs_solar   \n",
       "  80     residential_apartment_acs_electric   \n",
       "  76     residential_apartment_acs_electric   \n",
       "  72     residential_apartment_acs_electric   \n",
       "  81  residential_apartment_acs_natural_gas   \n",
       "  77  residential_apartment_acs_natural_gas   \n",
       "  73  residential_apartment_acs_natural_gas   \n",
       "  82      residential_apartment_acs_pliqgas   \n",
       "  78      residential_apartment_acs_pliqgas   \n",
       "  74      residential_apartment_acs_pliqgas   \n",
       "  83        residential_apartment_acs_solar   \n",
       "  79        residential_apartment_acs_solar   \n",
       "  75        residential_apartment_acs_solar   \n",
       "  \n",
       "     variable_trajectory_group_trajectory_type  time_series_id         0  \\\n",
       "  8                                        mix               0  0.000000   \n",
       "  4                      trajectory_boundary_0               0  0.033951   \n",
       "  0                      trajectory_boundary_1               0  0.033951   \n",
       "  9                                        mix               0  0.000000   \n",
       "  5                      trajectory_boundary_0               0  0.636875   \n",
       "  1                      trajectory_boundary_1               0  0.636875   \n",
       "  10                                       mix               0  0.000000   \n",
       "  6                      trajectory_boundary_0               0  0.329174   \n",
       "  2                      trajectory_boundary_1               0  0.329174   \n",
       "  11                                       mix               0  0.000000   \n",
       "  7                      trajectory_boundary_0               0  0.000000   \n",
       "  3                      trajectory_boundary_1               0  0.000000   \n",
       "  80                                       mix               1  0.000000   \n",
       "  76                     trajectory_boundary_0               1  0.033951   \n",
       "  72                     trajectory_boundary_1               1  0.033951   \n",
       "  81                                       mix               1  0.000000   \n",
       "  77                     trajectory_boundary_0               1  0.636875   \n",
       "  73                     trajectory_boundary_1               1  0.636875   \n",
       "  82                                       mix               1  0.000000   \n",
       "  78                     trajectory_boundary_0               1  0.329174   \n",
       "  74                     trajectory_boundary_1               1  0.329174   \n",
       "  83                                       mix               1  0.000000   \n",
       "  79                     trajectory_boundary_0               1  0.000000   \n",
       "  75                     trajectory_boundary_1               1  0.000000   \n",
       "  \n",
       "             1         2         3         4         5         6  ...        26  \\\n",
       "  8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "  4   0.033951  0.033951  0.033951  0.065521  0.092224  0.115848  ...  0.266597   \n",
       "  0   0.033951  0.033951  0.033951  0.065521  0.092224  0.115848  ...  0.266597   \n",
       "  9   0.000000  0.000000  0.000000  0.000000  1.000000  1.000000  ...  0.597930   \n",
       "  5   0.636875  0.636875  0.636875  0.629283  0.630000  0.630000  ...  0.380000   \n",
       "  1   0.636875  0.636875  0.636875  0.629283  0.596913  0.567921  ...  0.040000   \n",
       "  10  0.000000  0.000000 -0.003588 -0.005873 -0.003462 -0.001577  ... -0.000100   \n",
       "  6   0.329174  0.329174  0.329174  0.305197  0.267734  0.234893  ...  0.017846   \n",
       "  2   0.329174  0.329174  0.320000  0.300000  0.260000  0.220000  ...  0.000000   \n",
       "  11  0.000000  0.000000 -0.600000 -0.600000  0.846612  0.780351  ...  0.572285   \n",
       "  7   0.000000  0.000000  0.002887  0.003882  0.005208  0.015035  ...  0.211562   \n",
       "  3   0.000000  0.000000  0.007698  0.010352  0.050000  0.100000  ...  0.564167   \n",
       "  80  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "  76  0.033951  0.033951  0.033951  0.065521  0.092224  0.115848  ...  0.266597   \n",
       "  72  0.033951  0.033951  0.033951  0.065521  0.092224  0.115848  ...  0.266597   \n",
       "  81  0.000000  0.000000  0.000000  0.000000  1.000000  1.000000  ...  0.597930   \n",
       "  77  0.636875  0.636875  0.636875  0.629283  0.630000  0.630000  ...  0.380000   \n",
       "  73  0.636875  0.636875  0.636875  0.629283  0.596913  0.567921  ...  0.040000   \n",
       "  82  0.000000  0.000000 -0.003588 -0.005873 -0.003462 -0.001577  ... -0.000100   \n",
       "  78  0.329174  0.329174  0.329174  0.305197  0.267734  0.234893  ...  0.017846   \n",
       "  74  0.329174  0.329174  0.320000  0.300000  0.260000  0.220000  ...  0.000000   \n",
       "  83  0.000000  0.000000 -0.600000 -0.600000  0.846612  0.780351  ...  0.572285   \n",
       "  79  0.000000  0.000000  0.002887  0.003882  0.005208  0.015035  ...  0.211562   \n",
       "  75  0.000000  0.000000  0.007698  0.010352  0.050000  0.100000  ...  0.564167   \n",
       "  \n",
       "            27        28        29        30        31        32        33  \\\n",
       "  8  -0.001726 -0.000654 -0.000466 -0.000318 -0.000240 -0.000207 -0.000170   \n",
       "  4   0.286608  0.283316  0.280108  0.276975  0.273916  0.270928  0.268004   \n",
       "  0   0.270000  0.240000  0.220000  0.190000  0.160000  0.140000  0.110000   \n",
       "  9   0.723622  0.748304  0.773578  0.805819  0.832001  0.863607  0.890895   \n",
       "  5   0.340000  0.330000  0.320000  0.320000  0.310000  0.310000  0.300000   \n",
       "  1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "  10 -0.000100 -0.000100 -0.000100 -0.000100 -0.000100 -0.000100 -0.000100   \n",
       "  6   0.017265  0.015831  0.014421  0.013038  0.011679  0.010344  0.009034   \n",
       "  2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "  11  0.659086  0.643560  0.628493  0.613860  0.599638  0.585801  0.572326   \n",
       "  7   0.221389  0.231215  0.241042  0.250868  0.260694  0.270521  0.280347   \n",
       "  3   0.590370  0.616574  0.642778  0.668981  0.695185  0.721389  0.747593   \n",
       "  80 -0.001726 -0.000654 -0.000466 -0.000318 -0.000240 -0.000207 -0.000170   \n",
       "  76  0.286608  0.283316  0.280108  0.276975  0.273916  0.270928  0.268004   \n",
       "  72  0.270000  0.240000  0.220000  0.190000  0.160000  0.140000  0.110000   \n",
       "  81  0.723622  0.748304  0.773578  0.805819  0.832001  0.863607  0.890895   \n",
       "  77  0.340000  0.330000  0.320000  0.320000  0.310000  0.310000  0.300000   \n",
       "  73  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "  82 -0.000100 -0.000100 -0.000100 -0.000100 -0.000100 -0.000100 -0.000100   \n",
       "  78  0.017265  0.015831  0.014421  0.013038  0.011679  0.010344  0.009034   \n",
       "  74  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "  83  0.659086  0.643560  0.628493  0.613860  0.599638  0.585801  0.572326   \n",
       "  79  0.221389  0.231215  0.241042  0.250868  0.260694  0.270521  0.280347   \n",
       "  75  0.590370  0.616574  0.642778  0.668981  0.695185  0.721389  0.747593   \n",
       "  \n",
       "            34        35  \n",
       "  8  -0.000143 -0.000130  \n",
       "  4   0.265149  0.262357  \n",
       "  0   0.080000  0.060000  \n",
       "  9   0.919279  0.950639  \n",
       "  5   0.290000  0.290000  \n",
       "  1   0.000000  0.000000  \n",
       "  10 -0.000100 -0.000100  \n",
       "  6   0.007746  0.006481  \n",
       "  2   0.000000  0.000000  \n",
       "  11  0.559197  0.546399  \n",
       "  7   0.290174  0.300000  \n",
       "  3   0.773796  0.800000  \n",
       "  80 -0.000143 -0.000130  \n",
       "  76  0.265149  0.262357  \n",
       "  72  0.080000  0.060000  \n",
       "  81  0.919279  0.950639  \n",
       "  77  0.290000  0.290000  \n",
       "  73  0.000000  0.000000  \n",
       "  82 -0.000100 -0.000100  \n",
       "  78  0.007746  0.006481  \n",
       "  74  0.000000  0.000000  \n",
       "  83  0.559197  0.546399  \n",
       "  79  0.290174  0.300000  \n",
       "  75  0.773796  0.800000  \n",
       "  \n",
       "  [24 rows x 39 columns],\n",
       "  'baseline_strategy_array': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -1.72573200e-03, -6.54072000e-04, -4.66007000e-04,\n",
       "          -3.18454000e-04, -2.40455000e-04, -2.06929000e-04,\n",
       "          -1.69618000e-04, -1.43209000e-04, -1.29651000e-04],\n",
       "         [ 3.39505730e-02,  3.39505730e-02,  3.39505730e-02,\n",
       "           3.39505730e-02,  6.55207030e-02,  9.22236530e-02,\n",
       "           1.15847999e-01,  1.36903799e-01,  1.55755608e-01,\n",
       "           1.72765474e-01,  1.88158474e-01,  2.02185934e-01,\n",
       "           2.15045243e-01,  2.26624645e-01,  2.37470277e-01,\n",
       "           2.46778859e-01,  2.57305810e-01,  2.57674907e-01,\n",
       "           2.63907466e-01,  2.71325985e-01,  2.78337611e-01,\n",
       "           2.85697952e-01,  2.89184045e-01,  2.83167728e-01,\n",
       "           2.77392986e-01,  2.71847441e-01,  2.66596711e-01,\n",
       "           2.86607902e-01,  2.83315663e-01,  2.80108090e-01,\n",
       "           2.76974892e-01,  2.73915649e-01,  2.70927809e-01,\n",
       "           2.68004360e-01,  2.65148641e-01,  2.62356663e-01],\n",
       "         [ 3.39505730e-02,  3.39505730e-02,  3.39505730e-02,\n",
       "           3.39505730e-02,  6.55207030e-02,  9.22236530e-02,\n",
       "           1.15847999e-01,  1.36903799e-01,  1.55755608e-01,\n",
       "           1.72765474e-01,  1.88158474e-01,  2.02185934e-01,\n",
       "           2.15045243e-01,  2.26624645e-01,  2.37470277e-01,\n",
       "           2.46778859e-01,  2.57305810e-01,  2.57674907e-01,\n",
       "           2.63907466e-01,  2.71325985e-01,  2.78337611e-01,\n",
       "           2.85697952e-01,  2.89184045e-01,  2.83167728e-01,\n",
       "           2.77392986e-01,  2.71847441e-01,  2.66596711e-01,\n",
       "           2.70000000e-01,  2.40000000e-01,  2.20000000e-01,\n",
       "           1.90000000e-01,  1.60000000e-01,  1.40000000e-01,\n",
       "           1.10000000e-01,  8.00000000e-02,  6.00000000e-02],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "           1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "           1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "           1.00000000e+00,  1.00000000e+00,  9.51064058e-01,\n",
       "           8.54606427e-01,  8.49497665e-01,  7.68224740e-01,\n",
       "           7.44057569e-01,  7.13344341e-01,  7.15129618e-01,\n",
       "           6.98291397e-01,  7.02111621e-01,  6.77301790e-01,\n",
       "           6.52546387e-01,  6.20224773e-01,  5.97930309e-01,\n",
       "           7.23621756e-01,  7.48304373e-01,  7.73577619e-01,\n",
       "           8.05819256e-01,  8.32001294e-01,  8.63606648e-01,\n",
       "           8.90895280e-01,  9.19278503e-01,  9.50638690e-01],\n",
       "         [ 6.36875280e-01,  6.36875280e-01,  6.36875280e-01,\n",
       "           6.36875280e-01,  6.29282600e-01,  6.30000000e-01,\n",
       "           6.30000000e-01,  6.30000000e-01,  6.30000000e-01,\n",
       "           6.30000000e-01,  6.20000000e-01,  6.20000000e-01,\n",
       "           6.20000000e-01,  6.10000000e-01,  6.00000000e-01,\n",
       "           5.90000000e-01,  5.80000000e-01,  5.00000000e-01,\n",
       "           4.70000000e-01,  4.50000000e-01,  4.40000000e-01,\n",
       "           4.30000000e-01,  4.10000000e-01,  4.00000000e-01,\n",
       "           3.90000000e-01,  3.90000000e-01,  3.80000000e-01,\n",
       "           3.40000000e-01,  3.30000000e-01,  3.20000000e-01,\n",
       "           3.20000000e-01,  3.10000000e-01,  3.10000000e-01,\n",
       "           3.00000000e-01,  2.90000000e-01,  2.90000000e-01],\n",
       "         [ 6.36875280e-01,  6.36875280e-01,  6.36875280e-01,\n",
       "           6.36875280e-01,  6.29282600e-01,  5.96913024e-01,\n",
       "           5.67921207e-01,  5.42215853e-01,  5.19373333e-01,\n",
       "           4.98802283e-01,  4.80208720e-01,  4.63081260e-01,\n",
       "           4.47525961e-01,  4.32169692e-01,  4.10000000e-01,\n",
       "           3.70000000e-01,  3.50000000e-01,  2.50000000e-01,\n",
       "           2.10000000e-01,  1.80000000e-01,  1.60000000e-01,\n",
       "           1.40000000e-01,  1.30000000e-01,  1.10000000e-01,\n",
       "           9.00000000e-02,  6.00000000e-02,  4.00000000e-02,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -3.58806300e-03, -5.87289900e-03, -3.46185500e-03,\n",
       "          -1.57716800e-03, -8.06870000e-04, -4.60085000e-04,\n",
       "          -4.44306000e-04, -2.50788000e-04, -2.12857000e-04,\n",
       "          -1.72712000e-04, -1.34398000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04],\n",
       "         [ 3.29174147e-01,  3.29174147e-01,  3.29174147e-01,\n",
       "           3.29174147e-01,  3.05196696e-01,  2.67733826e-01,\n",
       "           2.34893367e-01,  2.05464384e-01,  1.78879728e-01,\n",
       "           1.54852753e-01,  1.33054734e-01,  1.13164593e-01,\n",
       "           9.50117880e-02,  7.81421660e-02,  6.26661670e-02,\n",
       "           4.83529130e-02,  3.91120030e-02,  2.93313980e-02,\n",
       "           2.12115860e-02,  1.37771420e-02,  6.78964000e-03,\n",
       "           2.13159000e-04,  5.95613900e-03,  9.12335800e-03,\n",
       "           1.21681390e-02,  1.51009410e-02,  1.78457740e-02,\n",
       "           1.72645000e-02,  1.58306290e-02,  1.44213650e-02,\n",
       "           1.30378610e-02,  1.16789360e-02,  1.03440240e-02,\n",
       "           9.03365000e-03,  7.74585600e-03,  6.48094100e-03],\n",
       "         [ 3.29174147e-01,  3.29174147e-01,  3.29174147e-01,\n",
       "           3.20000000e-01,  3.00000000e-01,  2.60000000e-01,\n",
       "           2.20000000e-01,  1.80000000e-01,  1.40000000e-01,\n",
       "           1.20000000e-01,  8.00000000e-02,  6.00000000e-02,\n",
       "           4.00000000e-02,  2.00000000e-02,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -6.00000166e-01, -5.99999907e-01,  8.46612202e-01,\n",
       "           7.80350721e-01,  7.86483733e-01,  7.65961923e-01,\n",
       "           7.79918086e-01,  7.37187009e-01,  7.63646003e-01,\n",
       "           7.44306242e-01,  7.50691774e-01,  7.21943576e-01,\n",
       "           7.15300578e-01,  7.40172319e-01,  6.91722855e-01,\n",
       "           6.94548127e-01,  6.77489025e-01,  6.82238570e-01,\n",
       "           6.88014756e-01,  6.76291108e-01,  6.49445766e-01,\n",
       "           6.22425220e-01,  5.96637333e-01,  5.72285131e-01,\n",
       "           6.59085624e-01,  6.43559904e-01,  6.28492873e-01,\n",
       "           6.13859973e-01,  5.99638014e-01,  5.85800878e-01,\n",
       "           5.72325516e-01,  5.59196937e-01,  5.46399294e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           2.88671600e-03,  3.88200300e-03,  5.20828200e-03,\n",
       "           1.50346720e-02,  2.48610630e-02,  3.46874530e-02,\n",
       "           4.45138440e-02,  5.43402350e-02,  6.41666250e-02,\n",
       "           7.39930160e-02,  8.38194060e-02,  9.36457970e-02,\n",
       "           1.03472188e-01,  1.13298578e-01,  1.23124969e-01,\n",
       "           1.32951360e-01,  1.42777750e-01,  1.52604141e-01,\n",
       "           1.62430531e-01,  1.72256922e-01,  1.82083313e-01,\n",
       "           1.91909703e-01,  2.01736094e-01,  2.11562484e-01,\n",
       "           2.21388875e-01,  2.31215266e-01,  2.41041656e-01,\n",
       "           2.50868047e-01,  2.60694438e-01,  2.70520828e-01,\n",
       "           2.80347219e-01,  2.90173609e-01,  3.00000000e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           7.69790800e-03,  1.03520090e-02,  5.00000000e-02,\n",
       "           1.00000000e-01,  1.40000000e-01,  1.80000000e-01,\n",
       "           2.10000000e-01,  2.50000000e-01,  2.70000000e-01,\n",
       "           3.00000000e-01,  3.20000000e-01,  3.50000000e-01,\n",
       "           3.70000000e-01,  3.80000000e-01,  4.00000000e-01,\n",
       "           4.10000000e-01,  4.30000000e-01,  4.40000000e-01,\n",
       "           4.50000000e-01,  4.60000000e-01,  4.85555500e-01,\n",
       "           5.11759209e-01,  5.37962917e-01,  5.64166625e-01,\n",
       "           5.90370334e-01,  6.16574042e-01,  6.42777750e-01,\n",
       "           6.68981458e-01,  6.95185167e-01,  7.21388875e-01,\n",
       "           7.47592583e-01,  7.73796292e-01,  8.00000000e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -1.72573200e-03, -6.54072000e-04, -4.66007000e-04,\n",
       "          -3.18454000e-04, -2.40455000e-04, -2.06929000e-04,\n",
       "          -1.69618000e-04, -1.43209000e-04, -1.29651000e-04],\n",
       "         [ 3.39505730e-02,  3.39505730e-02,  3.39505730e-02,\n",
       "           3.39505730e-02,  6.55207030e-02,  9.22236530e-02,\n",
       "           1.15847999e-01,  1.36903799e-01,  1.55755608e-01,\n",
       "           1.72765474e-01,  1.88158474e-01,  2.02185934e-01,\n",
       "           2.15045243e-01,  2.26624645e-01,  2.37470277e-01,\n",
       "           2.46778859e-01,  2.57305810e-01,  2.57674907e-01,\n",
       "           2.63907466e-01,  2.71325985e-01,  2.78337611e-01,\n",
       "           2.85697952e-01,  2.89184045e-01,  2.83167728e-01,\n",
       "           2.77392986e-01,  2.71847441e-01,  2.66596711e-01,\n",
       "           2.86607902e-01,  2.83315663e-01,  2.80108090e-01,\n",
       "           2.76974892e-01,  2.73915649e-01,  2.70927809e-01,\n",
       "           2.68004360e-01,  2.65148641e-01,  2.62356663e-01],\n",
       "         [ 3.39505730e-02,  3.39505730e-02,  3.39505730e-02,\n",
       "           3.39505730e-02,  6.55207030e-02,  9.22236530e-02,\n",
       "           1.15847999e-01,  1.36903799e-01,  1.55755608e-01,\n",
       "           1.72765474e-01,  1.88158474e-01,  2.02185934e-01,\n",
       "           2.15045243e-01,  2.26624645e-01,  2.37470277e-01,\n",
       "           2.46778859e-01,  2.57305810e-01,  2.57674907e-01,\n",
       "           2.63907466e-01,  2.71325985e-01,  2.78337611e-01,\n",
       "           2.85697952e-01,  2.89184045e-01,  2.83167728e-01,\n",
       "           2.77392986e-01,  2.71847441e-01,  2.66596711e-01,\n",
       "           2.70000000e-01,  2.40000000e-01,  2.20000000e-01,\n",
       "           1.90000000e-01,  1.60000000e-01,  1.40000000e-01,\n",
       "           1.10000000e-01,  8.00000000e-02,  6.00000000e-02],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "           1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "           1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "           1.00000000e+00,  1.00000000e+00,  9.51064058e-01,\n",
       "           8.54606427e-01,  8.49497665e-01,  7.68224740e-01,\n",
       "           7.44057569e-01,  7.13344341e-01,  7.15129618e-01,\n",
       "           6.98291397e-01,  7.02111621e-01,  6.77301790e-01,\n",
       "           6.52546387e-01,  6.20224773e-01,  5.97930309e-01,\n",
       "           7.23621756e-01,  7.48304373e-01,  7.73577619e-01,\n",
       "           8.05819256e-01,  8.32001294e-01,  8.63606648e-01,\n",
       "           8.90895280e-01,  9.19278503e-01,  9.50638690e-01],\n",
       "         [ 6.36875280e-01,  6.36875280e-01,  6.36875280e-01,\n",
       "           6.36875280e-01,  6.29282600e-01,  6.30000000e-01,\n",
       "           6.30000000e-01,  6.30000000e-01,  6.30000000e-01,\n",
       "           6.30000000e-01,  6.20000000e-01,  6.20000000e-01,\n",
       "           6.20000000e-01,  6.10000000e-01,  6.00000000e-01,\n",
       "           5.90000000e-01,  5.80000000e-01,  5.00000000e-01,\n",
       "           4.70000000e-01,  4.50000000e-01,  4.40000000e-01,\n",
       "           4.30000000e-01,  4.10000000e-01,  4.00000000e-01,\n",
       "           3.90000000e-01,  3.90000000e-01,  3.80000000e-01,\n",
       "           3.40000000e-01,  3.30000000e-01,  3.20000000e-01,\n",
       "           3.20000000e-01,  3.10000000e-01,  3.10000000e-01,\n",
       "           3.00000000e-01,  2.90000000e-01,  2.90000000e-01],\n",
       "         [ 6.36875280e-01,  6.36875280e-01,  6.36875280e-01,\n",
       "           6.36875280e-01,  6.29282600e-01,  5.96913024e-01,\n",
       "           5.67921207e-01,  5.42215853e-01,  5.19373333e-01,\n",
       "           4.98802283e-01,  4.80208720e-01,  4.63081260e-01,\n",
       "           4.47525961e-01,  4.32169692e-01,  4.10000000e-01,\n",
       "           3.70000000e-01,  3.50000000e-01,  2.50000000e-01,\n",
       "           2.10000000e-01,  1.80000000e-01,  1.60000000e-01,\n",
       "           1.40000000e-01,  1.30000000e-01,  1.10000000e-01,\n",
       "           9.00000000e-02,  6.00000000e-02,  4.00000000e-02,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -3.58806300e-03, -5.87289900e-03, -3.46185500e-03,\n",
       "          -1.57716800e-03, -8.06870000e-04, -4.60085000e-04,\n",
       "          -4.44306000e-04, -2.50788000e-04, -2.12857000e-04,\n",
       "          -1.72712000e-04, -1.34398000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04,\n",
       "          -1.00000000e-04, -1.00000000e-04, -1.00000000e-04],\n",
       "         [ 3.29174147e-01,  3.29174147e-01,  3.29174147e-01,\n",
       "           3.29174147e-01,  3.05196696e-01,  2.67733826e-01,\n",
       "           2.34893367e-01,  2.05464384e-01,  1.78879728e-01,\n",
       "           1.54852753e-01,  1.33054734e-01,  1.13164593e-01,\n",
       "           9.50117880e-02,  7.81421660e-02,  6.26661670e-02,\n",
       "           4.83529130e-02,  3.91120030e-02,  2.93313980e-02,\n",
       "           2.12115860e-02,  1.37771420e-02,  6.78964000e-03,\n",
       "           2.13159000e-04,  5.95613900e-03,  9.12335800e-03,\n",
       "           1.21681390e-02,  1.51009410e-02,  1.78457740e-02,\n",
       "           1.72645000e-02,  1.58306290e-02,  1.44213650e-02,\n",
       "           1.30378610e-02,  1.16789360e-02,  1.03440240e-02,\n",
       "           9.03365000e-03,  7.74585600e-03,  6.48094100e-03],\n",
       "         [ 3.29174147e-01,  3.29174147e-01,  3.29174147e-01,\n",
       "           3.20000000e-01,  3.00000000e-01,  2.60000000e-01,\n",
       "           2.20000000e-01,  1.80000000e-01,  1.40000000e-01,\n",
       "           1.20000000e-01,  8.00000000e-02,  6.00000000e-02,\n",
       "           4.00000000e-02,  2.00000000e-02,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          -6.00000166e-01, -5.99999907e-01,  8.46612202e-01,\n",
       "           7.80350721e-01,  7.86483733e-01,  7.65961923e-01,\n",
       "           7.79918086e-01,  7.37187009e-01,  7.63646003e-01,\n",
       "           7.44306242e-01,  7.50691774e-01,  7.21943576e-01,\n",
       "           7.15300578e-01,  7.40172319e-01,  6.91722855e-01,\n",
       "           6.94548127e-01,  6.77489025e-01,  6.82238570e-01,\n",
       "           6.88014756e-01,  6.76291108e-01,  6.49445766e-01,\n",
       "           6.22425220e-01,  5.96637333e-01,  5.72285131e-01,\n",
       "           6.59085624e-01,  6.43559904e-01,  6.28492873e-01,\n",
       "           6.13859973e-01,  5.99638014e-01,  5.85800878e-01,\n",
       "           5.72325516e-01,  5.59196937e-01,  5.46399294e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           2.88671600e-03,  3.88200300e-03,  5.20828200e-03,\n",
       "           1.50346720e-02,  2.48610630e-02,  3.46874530e-02,\n",
       "           4.45138440e-02,  5.43402350e-02,  6.41666250e-02,\n",
       "           7.39930160e-02,  8.38194060e-02,  9.36457970e-02,\n",
       "           1.03472188e-01,  1.13298578e-01,  1.23124969e-01,\n",
       "           1.32951360e-01,  1.42777750e-01,  1.52604141e-01,\n",
       "           1.62430531e-01,  1.72256922e-01,  1.82083313e-01,\n",
       "           1.91909703e-01,  2.01736094e-01,  2.11562484e-01,\n",
       "           2.21388875e-01,  2.31215266e-01,  2.41041656e-01,\n",
       "           2.50868047e-01,  2.60694438e-01,  2.70520828e-01,\n",
       "           2.80347219e-01,  2.90173609e-01,  3.00000000e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           7.69790800e-03,  1.03520090e-02,  5.00000000e-02,\n",
       "           1.00000000e-01,  1.40000000e-01,  1.80000000e-01,\n",
       "           2.10000000e-01,  2.50000000e-01,  2.70000000e-01,\n",
       "           3.00000000e-01,  3.20000000e-01,  3.50000000e-01,\n",
       "           3.70000000e-01,  3.80000000e-01,  4.00000000e-01,\n",
       "           4.10000000e-01,  4.30000000e-01,  4.40000000e-01,\n",
       "           4.50000000e-01,  4.60000000e-01,  4.85555500e-01,\n",
       "           5.11759209e-01,  5.37962917e-01,  5.64166625e-01,\n",
       "           5.90370334e-01,  6.16574042e-01,  6.42777750e-01,\n",
       "           6.68981458e-01,  6.95185167e-01,  7.21388875e-01,\n",
       "           7.47592583e-01,  7.73796292e-01,  8.00000000e-01]]),\n",
       "  'difference_arrays_by_strategy': {}})"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfl = pd.read_csv(\"/Users/jsyme/Documents/Projects/FY20/SWCHE102-1000/git/MultiSector_LTS_Chile/archive_runs/Chile_sector_package_2021_02_20_design_id-1/experimental_design_multi_sector.csv\")\n",
    "#list(dfl.columns)eerreeeeeee\n",
    "#var1.generate_future(, baseline_future_q = True)\n",
    "\n",
    "var1.data_table[var1.data_table[\"strategy_id\"] == 0][fields_ext].drop_duplicates()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this',)\n",
      "54\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#df_tmp[df_tmp[\"sector\"] == \"transport\"][\"variable\"].unique()\n",
    "#df_tmp[df_tmp[\"variable_trajectory_group\"] == 6][\"variable\"]\n",
    "var1.dict_id_values\n",
    "var1.dict_baseline_ids\n",
    "\n",
    "def test():\n",
    "    try:\n",
    "        raise Exception(\"this\")\n",
    "    except Exception as exc:\n",
    "        print(exc.args)\n",
    "        raise\n",
    "    finally:\n",
    "\n",
    "        print(\"54\")\n",
    "        pass\n",
    "\n",
    "        x = 5\n",
    "        print(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "ll = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No trajgroup found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-484-db433600a407>:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  a1 = (v1/v1.clip(*(0, 1)))#.nan_to_num(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.  , 1.  , 1.25],\n",
       "       [0.  , 1.  , 1.  ]])"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sampling_unit.mix_vecs(range(6), np.ones(6), [0.1, 0.1, 0.2, 0.8, 0.9, 0.99])\n",
    "#var1.apply_lhs(np.array([5, 3]))\n",
    "var2.apply_lhs([5, 2])\n",
    "\n",
    "set([x[0] for x in var1.ordered_trajectory_arrays.keys()])\n",
    "v1 = np.array([[1, 3, 5], [-1, 3, 1]])/4\n",
    "a1 = (v1/v1.clip(*(0, 1)))#.nan_to_num(0)\n",
    "a1[np.abs(a1) == np.inf] = 0\n",
    "a1\n",
    "#type(pyd.lhs(4, 10)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-3d682440c941>:3: UserWarning: warning!\n",
      "  warnings.warn(\"warning!\")\n"
     ]
    }
   ],
   "source": [
    "ss = list(var1.id_coordinates)\n",
    "ss.sort()\n",
    "warnings.warn(\"warning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = sampling_unit(df_tmp[df_tmp[\"variable_trajectory_group\"] == None], {\"time_series_id\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var1.id_coordinates\n",
    "df_prepend = df_tmp[df_tmp[\"variable_specification\"] == \"manejo_holistico_de_gando\"].copy()\n",
    "df_append = df_tmp[(df_tmp[\"variable_specification\"] == \"transport_truck_investment_cost_hydrogen\") & (df_tmp[\"strategy_id\"] > 0)].copy()\n",
    "\n",
    "df_test = pd.concat([df_prepend, df_append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[df_tmp[\"parameter_constant_q\"].isin([1.0]) & df_tmp[\"\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_temp = {1: \"this is\", 2: \"this isnt\", 3: \"dont\"}\n",
    "[k for k,v in dict_temp.items() if \"this\" in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.build_dict(df_tmp[[\"time_series_id\", \"strategy_id\", \"type\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([\"01\", \"02\"], [1, 2])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
