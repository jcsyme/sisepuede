{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsyme/Documents/Projects/git_jbus/sisepuede/python/model_attributes.py:2635: UserWarning: Invalid subsector attribute 'key_varreqs_partial'. Valid return type values are:'pycategory_primary', 'abv_subsector', 'sector', 'abv_sector', 'key_varreqs_all'\n",
      "  warnings.warn(f\"Invalid subsector attribute '{return_type}'. Valid return type values are:{valid_rts}\")\n",
      "/Users/jsyme/Documents/Projects/git_jbus/sisepuede/python/model_attributes.py:2392: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for desig, df in df_by_designation:\n"
     ]
    }
   ],
   "source": [
    "import os, os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import model_attributes as ma\n",
    "from attribute_table import AttributeTable\n",
    "import setup_analysis as sa\n",
    "import support_classes as sc\n",
    "import support_functions as sf\n",
    "import importlib\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import rioxarray as rx\n",
    "import itertools\n",
    "import model_afolu as mafl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/3ll2cn6d1hdcs6gjqxr2jx5d2hffc9/T/ipykernel_18255/1833089009.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_check[\"count\"] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>iso_alpha_3</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5683</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5684</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>4</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count iso_alpha_3  year\n",
       "5663      4         NLD  2015\n",
       "5685      4         NLD  2037\n",
       "5679      4         NLD  2031\n",
       "5680      4         NLD  2032\n",
       "5681      4         NLD  2033\n",
       "5682      4         NLD  2034\n",
       "5683      4         NLD  2035\n",
       "5684      4         NLD  2036\n",
       "5686      4         NLD  2038\n",
       "5677      4         NLD  2029\n",
       "5687      4         NLD  2039\n",
       "5688      4         NLD  2040\n",
       "5689      4         NLD  2041\n",
       "5690      4         NLD  2042\n",
       "5691      4         NLD  2043\n",
       "5692      4         NLD  2044\n",
       "5678      4         NLD  2030\n",
       "5676      4         NLD  2028\n",
       "5694      4         NLD  2046\n",
       "5660      4         NLD  2012\n",
       "5666      4         NLD  2018\n",
       "5665      4         NLD  2017\n",
       "5664      4         NLD  2016\n",
       "5669      4         NLD  2021\n",
       "5662      4         NLD  2014\n",
       "5661      4         NLD  2013\n",
       "5659      4         NLD  2011\n",
       "5675      4         NLD  2027\n",
       "5658      4         NLD  2010\n",
       "5670      4         NLD  2022\n",
       "5671      4         NLD  2023\n",
       "5672      4         NLD  2024\n",
       "5673      4         NLD  2025\n",
       "5674      4         NLD  2026\n",
       "5693      4         NLD  2045\n",
       "5695      4         NLD  2047\n",
       "5668      4         NLD  2020\n",
       "5698      4         NLD  2050\n",
       "5696      4         NLD  2048\n",
       "5667      4         NLD  2019\n",
       "5697      4         NLD  2049"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_soil = pd.read_csv(sa.fp_csv_soc_fields_by_country_simple)\n",
    "fields_index = [\"iso_alpha_3\", \"year\"]\n",
    "df_check = df_soil[fields_index]\n",
    "df_check[\"count\"] = 1\n",
    "agg = sf.simple_df_agg(\n",
    "    df_check, \n",
    "    fields_index,\n",
    "    {\"count\": \"sum\"}\n",
    ").sort_values(by = [\"count\"], ascending = False)\n",
    "\n",
    "agg[agg[\"count\"] > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsyme/Documents/Projects/git_jbus/sisepuede/python/support_functions.py:1354: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for i, df in df_in_grouped:\n",
      "/Users/jsyme/Documents/Projects/git_jbus/sisepuede/python/support_functions.py:1354: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for i, df in df_in_grouped:\n"
     ]
    }
   ],
   "source": [
    "dir_data = \"/Users/jsyme/Documents/Projects/FY21/SWCHE131_1000/Data/AFOLU\"\n",
    "\n",
    "# set names \n",
    "fn_climates = \"kc_1984_2013.tif\"\n",
    "fn_countries = \"WB_countries_Admin0_10m\"\n",
    "fn_cw = \"values_info_with_cw_kc_1984_2013.csv\"\n",
    "\n",
    "fp_climates = os.path.join(dir_data, fn_climates)\n",
    "fp_countries = os.path.join(dir_data, fn_countries, f\"{fn_countries}.shp\")\n",
    "fp_cw = os.path.join(dir_data, fn_cw)\n",
    "\n",
    "model_afolu = mafl.AFOLU(sa.model_attributes)\n",
    "regions = sc.Regions(sa.model_attributes)\n",
    "time_periods = sc.TimePeriods(sa.model_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_array = rx.open_rasterio(fp_climates)\n",
    "df_climates = rx_array[0].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 43200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_climates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert geotiff to dataframe\n",
    "rx_array = rx.open_rasterio(fp_climates)\n",
    "df_climates = rx_array[0].to_pandas()\n",
    "# retrieve climate categories\n",
    "df_climate_cats = pd.read_csv(fp_cw, sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reshape_df_climate(\n",
    "    df_input: pd.DataFrame,\n",
    "    vec_x: np.ndarray,\n",
    "    vec_y: np.ndarray,\n",
    "    field_val: str = \"value\",\n",
    "    field_x: str = \"x\",\n",
    "    field_y: str = \"y\",\n",
    "    flag_empty: int = flag_empty,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reshape df soils without having to melt and filter\n",
    "    \"\"\"\n",
    "    arr = np.array(df_input)\n",
    "\n",
    "    w = np.where(arr != flag_empty)\n",
    "    \n",
    "    # get indexing\n",
    "    col_vals = arr[w[0], w[1]]\n",
    "    col_x = vec_x[w[1]]\n",
    "    col_y = vec_y[w[0]]\n",
    "    \n",
    "    df_out = pd.DataFrame(\n",
    "        {\n",
    "            field_x: col_x,\n",
    "            field_y: col_y,\n",
    "            field_val: col_vals\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "flag_empty = df_climates.iloc[0,0]\n",
    "vec_x = np.array(df_climates.columns)\n",
    "vec_y = np.array(df_climates.index)\n",
    "\n",
    "\n",
    "dfc = reshape_df_climate(\n",
    "    df_climates,\n",
    "    vec_x,\n",
    "    vec_y,\n",
    "    flag_empty = flag_empty\n",
    ")\n",
    "\n",
    "crs_climates = \"EPSG:4326\"\n",
    "gdf_climates_cut = dfc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag_empty = -3.4e+38\n",
    "#np.where(np.array(df_climates.iloc[0:5, 0:5]) == )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_climates = df_climates.reset_index()#[-179.97083333333333].unique()\n",
    "dfc = pd.melt(df_climates, [\"y\"]);\n",
    "val = float(dfc[\"value\"].iloc[0])\n",
    "dfc = dfc[dfc[\"value\"] != val].reset_index(drop = True)\n",
    "\n",
    "# set some bounds\n",
    "# http://bboxfinder.com/#-55.776573,-126.386719,33.431441,-33.398438\n",
    "x_max = -34\n",
    "x_min = -119\n",
    "y_max = 33\n",
    "y_min = -58\n",
    "# filter out\n",
    "dfc2 = dfc[\n",
    "    (dfc[\"x\"] <= x_max) & \n",
    "    (dfc[\"x\"] >= x_min) & \n",
    "    (dfc[\"y\"] <= y_max) & \n",
    "    (dfc[\"y\"] >= y_min)\n",
    "].reset_index(drop = True)\n",
    "\n",
    "# create points with climates\n",
    "gdf_climates = gpd.GeoDataFrame(\n",
    "    dfc2, \n",
    "    geometry = gpd.points_from_xy(dfc2[\"x\"], dfc2[\"y\"])\n",
    ")\n",
    "gdf_climates.crs = \"EPSG:4326\"\n",
    "gdf_climates_cut = gdf_climates.copy()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload with filter\n",
    "if False:\n",
    "    \n",
    "\n",
    "    dfc = pd.read_csv(os.path.join(dir_read, \"kcc_coords_index.csv\"), skiprows = inds_drop)\n",
    "    \n",
    "    if False:\n",
    "\n",
    "        crs_climates = \"EPSG:4326\"\n",
    "\n",
    "        gdf_climates = gpd.GeoDataFrame(\n",
    "            dfc,\n",
    "            geometry = gpd.points_from_xy(dfc[\"x\"], dfc[\"y\"], crs = crs_climates)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "if False:\n",
    "    regex_match = re.compile(\"kcc_by_country_(\\D*).csv\")\n",
    "    dir_read = os.path.join(dir_data, \"kcc_cells_merged_to_country\")\n",
    "    fls_read = sorted([x for x in os.listdir(dir_read) if regex_match.match(x) is not None])\n",
    "    isos_avail = [regex_match.match(x).groups()[0] for x in fls_read]\n",
    "    \n",
    "    field_index = \"index_right\"\n",
    "    inds_drop = []\n",
    "\n",
    "    fl_tmp = \"/Users/jsyme/Desktop/tmp.csv\"\n",
    "\n",
    "    #with open(fl_tmp, \"w+\") as fl:\n",
    "    for i, fl in enumerate(fls_read):\n",
    "        df_get = pd.read_csv(os.path.join(dir_read, fl))\n",
    "        if field_index in df_get.columns:\n",
    "            inds_drop += list(df_get[field_index])\n",
    "            #inds_drop_cur = \"\\n\".join([str(x) for x in inds_drop_cur])\n",
    "            #fl.writelines(inds_drop_cur)\n",
    "\n",
    "        print(f\"{i} countries complete\") if (i%25 == 0) else None\n",
    "        \n",
    "    \n",
    "    crs_climates = \"EPSG:4326\"\n",
    "\n",
    "    gdf_climates = gpd.GeoDataFrame(\n",
    "        dfc,\n",
    "        geometry = gpd.points_from_xy(dfc[\"x\"], dfc[\"y\"], crs = crs_climates)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get countries \n",
    "countries_keep = regions.all_isos#list(sa.model_attributes.dict_attributes.get(\"region\").table[\"category_name\"])\n",
    "gdf_world = gpd.read_file(fp_countries)\n",
    "\n",
    "# do some replacements to clean it up\n",
    "field_formal_name = \"FORMAL_EN\"\n",
    "dict_repl = {\n",
    "    \"French Republic\": \"FRA\",\n",
    "    \"Kingdom of Norway\": \"NOR\",\n",
    "    \"Republic of Kosovo\": \"XKX\",\n",
    "}\n",
    "inds = gdf_world[gdf_world[field_formal_name].isin(dict_repl.keys())].index\n",
    "gdf_world.loc[inds, field_en] = gdf_world.loc[inds][field_formal_name].replace(dict_repl)\n",
    "\n",
    "# some replacements\n",
    "field_en = \"ISO_A3\"\n",
    "gdf_world_red = gdf_world[gdf_world[field_en].isin(countries_keep)]\n",
    "gdf_lac = gdf_world[[field_en, \"geometry\"]]\n",
    "gdf_lac_bounds = gdf_lac.bounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minx</th>\n",
       "      <th>miny</th>\n",
       "      <th>maxx</th>\n",
       "      <th>maxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.012706</td>\n",
       "      <td>-10.922621</td>\n",
       "      <td>140.977627</td>\n",
       "      <td>5.910102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.645228</td>\n",
       "      <td>0.851370</td>\n",
       "      <td>119.278087</td>\n",
       "      <td>7.355780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-109.453725</td>\n",
       "      <td>-55.918504</td>\n",
       "      <td>-66.420806</td>\n",
       "      <td>-17.506588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-69.666492</td>\n",
       "      <td>-22.897258</td>\n",
       "      <td>-57.465661</td>\n",
       "      <td>-9.679821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-81.337558</td>\n",
       "      <td>-18.337746</td>\n",
       "      <td>-68.684252</td>\n",
       "      <td>-0.029093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-75.030832</td>\n",
       "      <td>18.395006</td>\n",
       "      <td>-75.002634</td>\n",
       "      <td>18.417263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-162.103627</td>\n",
       "      <td>5.869371</td>\n",
       "      <td>-162.057607</td>\n",
       "      <td>5.890245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-162.400177</td>\n",
       "      <td>6.430243</td>\n",
       "      <td>-162.385284</td>\n",
       "      <td>6.445136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-172.502553</td>\n",
       "      <td>-9.361749</td>\n",
       "      <td>-171.185658</td>\n",
       "      <td>-8.543227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-177.957997</td>\n",
       "      <td>-52.600313</td>\n",
       "      <td>178.843923</td>\n",
       "      <td>-29.221938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           minx       miny        maxx       maxy\n",
       "0     95.012706 -10.922621  140.977627   5.910102\n",
       "1     99.645228   0.851370  119.278087   7.355780\n",
       "2   -109.453725 -55.918504  -66.420806 -17.506588\n",
       "3    -69.666492 -22.897258  -57.465661  -9.679821\n",
       "4    -81.337558 -18.337746  -68.684252  -0.029093\n",
       "..          ...        ...         ...        ...\n",
       "246  -75.030832  18.395006  -75.002634  18.417263\n",
       "247 -162.103627   5.869371 -162.057607   5.890245\n",
       "248 -162.400177   6.430243 -162.385284   6.445136\n",
       "249 -172.502553  -9.361749 -171.185658  -8.543227\n",
       "250 -177.957997 -52.600313  178.843923 -29.221938\n",
       "\n",
       "[251 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"FRA\" in gdf_world[field_en]#[~gdf_lac[field_en].isin(isos_avail)][field_en].unique()\n",
    "#[x for x in sorted(list(set(gdf_world[\"FORMAL_EN\"].dropna()))) if (\"fr\" in x.lower())]\n",
    "\n",
    "#gdf_world[~gdf_world[field_en].isin(isos_avail)][[\"FORMAL_EN\"]].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.58"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_gdf(\n",
    "    df_in: pd.DataFrame,\n",
    "    crs: str = crs_climates,\n",
    "    field_x: str = \"x\",\n",
    "    field_y: str = \"y\",\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \n",
    "    vec_x = np.array(df_in[field_x])\n",
    "    vec_y = np.array(df_in[field_y])\n",
    "    \n",
    "    gdf_out = gpd.GeoDataFrame(\n",
    "        df_in, \n",
    "        geometry = [shapely.geometry.Point(*x) for x in zip(vec_x, vec_y)]\n",
    "    )\n",
    "    gdf_out.crs = crs\n",
    "    \n",
    "    return gdf_out\n",
    "    \n",
    "t0 = time.time()\n",
    "gdf_points2 = df_to_gdf(gdf_points)\n",
    "sf.get_time_elapsed(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "2.08\n"
     ]
    }
   ],
   "source": [
    "#sf.get_time_elapsed(t0)\n",
    "import shapely\n",
    "type(gdf_points2.iloc[0][\"geometry\"])\n",
    "\n",
    "vec_x = np.array(gdf_points[\"x\"])[0:100000]\n",
    "vec_y = np.array(gdf_points[\"y\"])[0:100000]\n",
    "\n",
    "t0 = time.time()\n",
    "xx = [shapely.geometry.Point(*x) for x in zip(vec_x, vec_y)]\n",
    "print(sf.get_time_elapsed(t0))\n",
    "\n",
    "t0 = time.time()\n",
    "xx2 = gpd.points_from_xy(vec_x, vec_y, crs = crs_climates)\n",
    "print(sf.get_time_elapsed(t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_world_red = gdf_world[\n",
    "    gdf_world[field_en].isin(countries_keep)\n",
    "    & ~gdf_world[field_en].isin(isos_avail)\n",
    "]\n",
    "gdf_lac = gdf_world_red[[field_en, \"geometry\"]]\n",
    "gdf_lac_bounds = gdf_lac.bounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying climate gdf...\n",
      "\n",
      "\n",
      "Starting country FRA\n",
      "--------------------------------------------------------------------------- (1/3)\n",
      "\n",
      "Filtering points...\n",
      "\n",
      "Merging points within bbox x = (-61.79784095039952, 55.85450280026407), y = (-21.370782159269197, 51.08754088370489) to country...\n",
      "\n",
      "Aggregating counts by climate...\n",
      "\n",
      "Appending output...\n",
      "Dropping indices...\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Country FRA complete in 58.79 seconds (59.0 seconds overall)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Starting country NOR\n",
      "--------------------------------------------------------------------------- (2/3)\n",
      "\n",
      "Filtering points...\n",
      "\n",
      "Merging points within bbox x = (-9.117421027858086, 33.64039147178903), y = (-54.462497654443155, 80.77008698082955) to country...\n",
      "\n",
      "Aggregating counts by climate...\n",
      "\n",
      "Appending output...\n",
      "Dropping indices...\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Country NOR complete in 39.93 seconds (99.0 seconds overall)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Starting country XKX\n",
      "--------------------------------------------------------------------------- (3/3)\n",
      "\n",
      "Filtering points...\n",
      "\n",
      "Merging points within bbox x = (20.02475142433883, 21.772758421563935), y = (41.84401031562362, 43.263070984038734) to country...\n",
      "\n",
      "Aggregating counts by climate...\n",
      "\n",
      "Appending output...\n",
      "Dropping indices...\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Country XKX complete in 1.38 seconds (100.0 seconds overall)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "sep = \"---\"*25\n",
    "print(\"Copying climate gdf...\\n\\n\")\n",
    "gdf_climates_cut = gdf_climates.copy()\n",
    "\n",
    "\n",
    "df_out = []\n",
    "df_agg_out = []\n",
    "t0 = time.time()\n",
    "list_times = [t0]\n",
    "n = len(gdf_lac_bounds)\n",
    "\n",
    "while i < n:\n",
    "    \n",
    "    # country\n",
    "    gdf_country = gdf_lac.iloc[i:(i + 1)]\n",
    "    bounds = gdf_lac_bounds.iloc[i:(i + 1)]\n",
    "\n",
    "    country = str(gdf_country[field_en].iloc[0])\n",
    "    maxx = float(bounds[\"maxx\"].iloc[0])\n",
    "    minx = float(bounds[\"minx\"].iloc[0])\n",
    "    maxy = float(bounds[\"maxy\"].iloc[0])\n",
    "    miny = float(bounds[\"miny\"].iloc[0])\n",
    "    \n",
    "    pos = i + 1\n",
    "    print(f\"Starting country {country}\\n{sep} ({pos}/{n})\\n\")\n",
    "    \n",
    "    # get points\n",
    "    print(\"Filtering points...\\n\")\n",
    "    gdf_points = gdf_climates_cut[\n",
    "        (gdf_climates_cut[\"x\"] <= maxx) &\n",
    "        (gdf_climates_cut[\"x\"] >= minx) &\n",
    "        (gdf_climates_cut[\"y\"] <= maxy) &\n",
    "        (gdf_climates_cut[\"y\"] >= miny)\n",
    "    ]\n",
    "    \n",
    "    if not isinstance(gdf_climates_cut, gpd.GeoDataFrame):\n",
    "        print(\"Converting to GeoDataFrame...\\n\")\n",
    "        gdf_points = gpd.GeoDataFrame(\n",
    "            gdf_points,\n",
    "            geometry = gpd.points_from_xy(gdf_points[\"x\"], gdf_points[\"y\"], crs = crs_climates)\n",
    "        )\n",
    "    \n",
    "    print(f\"Merging points within bbox x = ({minx}, {maxx}), y = ({miny}, {maxy}) to country...\\n\")\n",
    "    gdf_join = gpd.sjoin(\n",
    "        gdf_country, \n",
    "        gdf_points[[\"value\", \"geometry\"]].rename(columns = {\"value\": \"kcc\"}),\n",
    "        how = \"inner\"\n",
    "    ).drop(\"geometry\", axis = 1)\n",
    "    \n",
    "    \n",
    "    print(f\"Aggregating counts by climate...\\n\")\n",
    "    gdf_agg = gdf_join[[field_en, \"kcc\"]].copy()\n",
    "    gdf_agg[\"count\"] = 1\n",
    "    gdf_agg = (\n",
    "        gdf_agg[[field_en, \"kcc\", \"count\"]]\n",
    "        .groupby([field_en, \"kcc\"])\n",
    "        .agg(\n",
    "            {field_en: \"first\", \"kcc\": \"first\", \"count\": \"sum\"}\n",
    "        )\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(\"Appending output...\")\n",
    "    df_out.append(gdf_join)\n",
    "    df_agg_out.append(gdf_agg)\n",
    "    \n",
    "    \n",
    "    print(\"Dropping indices...\")\n",
    "    indices_to_drop = list(gdf_join[\"index_right\"])\n",
    "    gdf_climates_cut.drop(indices_to_drop, axis = 0, inplace = True)\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "    list_times.append(time.time())\n",
    "    t_delta = np.round(list_times[i] - list_times[i - 1], 2)\n",
    "    t_elapsed = np.round(list_times[i] - list_times[0])\n",
    "    \n",
    "    print(f\"\\n{sep}\\n\\nCountry {country} complete in {t_delta} seconds ({t_elapsed} seconds overall)\\n\\n{sep}\\n\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NOTE: CAN START HERE\n",
    "- Only need to unzip and load `os.path.join(dir_data, \"kcc_cells_merged_to_country\", \"kcc_coords_index.csv\")`\n",
    "- country-level values are stored in `os.path.join(dir_data, \"kcc_cells_merged_to_country\")` with name `f\"kcc_by_country_{iso}.csv\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    dfc\n",
    ").to_csv(\n",
    "    os.path.join(dir_data, \"kcc_cells_merged_to_country\", \"kcc_coords_index.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_out_full = pd.concat(df_out, axis = 0).reset_index(drop = True);\n",
    "df_out_agg = pd.concat(df_agg_out, axis = 0).reset_index(drop = True);\n",
    "\n",
    "# export output\n",
    "#df_out_full.to_csv(sa.fp_csv_kcc_cells_merged_to_country, index = None, encoding = \"UTF-8\")\n",
    "df_out_agg.to_csv(sa.fp_csv_kcc_cell_counts_by_country_kcc, index = None, encoding = \"UTF-8\")\n",
    "\"\"\"\n",
    "df_out_agg_original = pd.read_csv(sa.fp_csv_kcc_cell_counts_by_country_kcc)\n",
    "df_out_agg_out  = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            df_out_agg_original,\n",
    "            df_out_agg\n",
    "        ],\n",
    "        axis = 0\n",
    "    )\n",
    "    .sort_values(by = [field_en, \"kcc\"])\n",
    "    .reset_index(drop = True)\n",
    ")\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 'FRA' complete.\n",
      "\n",
      "country 'NOR' complete.\n",
      "\n",
      "country 'XKX' complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_exp = os.path.join(dir_data, \"kcc_cells_merged_to_country\")\n",
    "os.makedirs(dir_exp, exist_ok = True)\n",
    "\n",
    "for df in df_out:\n",
    "    iso = str(df[field_en].iloc[0])\n",
    "    fp_write = os.path.join(dir_exp, f\"kcc_by_country_{iso}.csv\")\n",
    "    df.drop(field_en, axis = 1).to_csv(fp_write, index = None, encoding = \"UTF-8\")\n",
    "    print(f\"country '{iso}' complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inds_drop\n",
    "#pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##\n",
    "##  BUILD FRACTIONS WET/DRY AND TEMPERATE/TROPICAL BY COUNTRY\n",
    "##\n",
    "\n",
    "df_out_agg[\"count\"] = df_out_agg[\"count\"].astype(int)\n",
    "\n",
    "# get total counts\n",
    "df_out_agg_totals = (\n",
    "    sf.simple_df_agg(\n",
    "        df_out_agg[[field_en, \"count\"]],\n",
    "        [field_en],\n",
    "        {\"count\": \"sum\"}\n",
    "    )\n",
    "    .rename(columns = {\"count\": \"total_count\"})\n",
    ")\n",
    "# \n",
    "df_climate_by_country = pd.merge(\n",
    "    df_out_agg, \n",
    "    df_climate_cats[[\"code_num\", \"wet_dry_cat\", \"temperate_tropical_cat\"]].rename(columns = {\"code_num\": \"kcc\"})\n",
    ")\n",
    "\n",
    "# break out by wet/dry and temperate/tropical\n",
    "df_climate_by_country_temptrop = df_climate_by_country.drop([\"wet_dry_cat\"], axis = 1)\n",
    "df_climate_by_country_wetdry = df_climate_by_country.drop([\"temperate_tropical_cat\"], axis = 1)\n",
    "all_countries = sorted(list(set(df_climate_by_country[field_en])))\n",
    "\n",
    "# loop over different splits\n",
    "fields_loop = [\"wet_dry_cat\", \"temperate_tropical_cat\"]\n",
    "dict_df_climate_aggs = {}\n",
    "\n",
    "\n",
    "if True:\n",
    "    for field in fields_loop:\n",
    "\n",
    "        fields_grp = [field_en, field]\n",
    "        fields_dat = [\"count\"]\n",
    "\n",
    "        all_vals = sorted(list(set(df_climate_by_country[field])))\n",
    "        df_tmp = df_climate_by_country.drop([x for x in fields_loop if (x != field)], axis = 1)\n",
    "        dict_agg = dict(zip(fields_grp, [\"first\" for x in fields_grp]))\n",
    "        dict_agg.update(dict(zip(fields_dat, [\"sum\" for x in fields_dat])))\n",
    "\n",
    "        df_tmp = df_tmp[fields_grp + fields_dat].groupby(fields_grp).agg(dict_agg).reset_index(drop = True)\n",
    "        df_expand = pd.DataFrame(itertools.product(all_countries, all_vals), columns = [field_en, field])\n",
    "        df_expand = pd.merge(df_expand, df_out_agg_totals, how = \"left\").fillna(0)\n",
    "\n",
    "        df_tmp = pd.merge(df_expand, df_tmp, how = \"left\").fillna(0)\n",
    "        df_tmp[\"frac\"] = np.array(df_tmp[\"count\"])/np.array(df_tmp[\"total_count\"])\n",
    "        df_tmp.rename(columns = {field_en: \"country\"}, inplace = True)\n",
    "\n",
    "\n",
    "        # get pivot\n",
    "        df_piv = pd.pivot(\n",
    "            df_tmp[[\"country\", field, \"frac\"]],\n",
    "            index = [\"country\"],\n",
    "            columns = [field], \n",
    "            values = [\"frac\"]\n",
    "        ).reset_index()\n",
    "        df_piv.columns = df_piv.columns.to_flat_index()\n",
    "        dict_rnm = dict([(x, x[1].replace(\")\", \"\").strip()) for x in df_piv.columns if (x[1] != \"\")])\n",
    "        dict_rnm.update({(\"country\", \"\"): \"country\"})\n",
    "        df_piv.rename(columns = dict_rnm, inplace = True)\n",
    "\n",
    "        dict_df_climate_aggs.update({field: df_piv})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  TEMPERATE/TROPICAL SPLITS\n",
    "\n",
    "varlist_tt = []\n",
    "# ag temp/trop vars\n",
    "varlist_tt += sa.model_attributes.build_variable_fields(model_afolu.modvar_agrc_frac_temperate)\n",
    "varlist_tt += sa.model_attributes.build_variable_fields(model_afolu.modvar_agrc_frac_tropical)\n",
    "# frst temp/trop vars\n",
    "varlist_tt += sa.model_attributes.build_variable_fields(model_afolu.modvar_frst_frac_temperate_nutrient_rich)\n",
    "varlist_tt += sa.model_attributes.build_variable_fields(model_afolu.modvar_frst_frac_temperate_nutrient_poor)\n",
    "varlist_tt += sa.model_attributes.build_variable_fields(model_afolu.modvar_frst_frac_tropical)\n",
    "# lndu temp/trop vars\n",
    "varlist_tt += sa.model_attributes.build_variable_fields(model_afolu.modvar_lndu_frac_temperate)\n",
    "varlist_tt += sa.model_attributes.build_variable_fields(model_afolu.modvar_lndu_frac_tropical)\n",
    "\n",
    "\n",
    "##  WET/DRY SPLITS\n",
    "\n",
    "varlist_wd = []\n",
    "# ag temp/trop vars\n",
    "varlist_wd += sa.model_attributes.build_variable_fields(model_afolu.modvar_agrc_frac_wet)\n",
    "varlist_wd += sa.model_attributes.build_variable_fields(model_afolu.modvar_agrc_frac_dry)\n",
    "# lndu temp/trop vars\n",
    "varlist_wd += sa.model_attributes.build_variable_fields(model_afolu.modvar_lndu_frac_wet)\n",
    "varlist_wd += sa.model_attributes.build_variable_fields(model_afolu.modvar_lndu_frac_dry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_years = pd.DataFrame({time_periods.field_year: range(2010, time_periods.year_max + 1)})\n",
    "\n",
    "df_ret = dict_df_climate_aggs[field][[\"country\"]].copy()\n",
    "\n",
    "for field in dict_df_climate_aggs.keys():\n",
    "    \n",
    "    loop = varlist_tt if (field == \"temperate_tropical_cat\") else varlist_wd\n",
    "    for var in loop:\n",
    "        if field == \"temperate_tropical_cat\":\n",
    "            fld = \"temperate\" if (\"temperate\" in var) else (\"tropical\")\n",
    "        else:\n",
    "            fld = \"wet\" if (\"wet\" in var) else \"dry\"\n",
    "        div = 2 if ((\"nutrient_poor\" in var) or (\"nutrient_rich\" in var)) else 1\n",
    "        df_merge = dict_df_climate_aggs[field][[\"country\", fld]].copy().rename(columns = {fld: var})\n",
    "        df_ret = pd.merge(df_ret, df_merge)\n",
    "        df_ret[var] = np.array(df_ret[var])/div\n",
    "\n",
    "# merge in time period\n",
    "df_ret = sf.explode_merge(\n",
    "    df_years,\n",
    "    df_ret\n",
    ")\n",
    "df_ret = time_periods.years_to_tps(df_ret)\n",
    "df_ret.rename(columns = {\"country\": regions.field_iso}, inplace = True)\n",
    "fields_sort = [regions.field_iso, time_periods.field_time_period, time_periods.field_year]\n",
    "\n",
    "df_ret = (\n",
    "    df_ret[fields_sort + sorted([x for x in df_ret.columns if (x not in fields_sort)])]\n",
    "    .sort_values(by = fields_sort)\n",
    "    .reset_index(drop = True)\n",
    ")\n",
    "\n",
    "if False:\n",
    "\n",
    "    df_ret.to_csv(\n",
    "        sa.fp_csv_climate_fields_by_country_simple, index = None, encoding = \"UTF-8\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[[fields_sort] + sorted([x for x in df_ret.columns if (x not in fields_sort)])]\n",
    "df_ret_original = pd.read_csv(sa.fp_csv_climate_fields_by_country_simple)\n",
    "df_ret_out  = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            df_ret_original,\n",
    "            df_ret\n",
    "        ],\n",
    "        axis = 0\n",
    "    )\n",
    "    .sort_values(by = [regions.field_iso, time_periods.field_year])\n",
    "    .reset_index(drop = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>time_period</th>\n",
       "      <th>frac_agrc_bevs_and_spices_cl1_temperate</th>\n",
       "      <th>frac_agrc_bevs_and_spices_cl1_tropical</th>\n",
       "      <th>frac_agrc_bevs_and_spices_cl2_dry</th>\n",
       "      <th>frac_agrc_bevs_and_spices_cl2_wet</th>\n",
       "      <th>frac_agrc_cereals_cl1_temperate</th>\n",
       "      <th>frac_agrc_cereals_cl1_tropical</th>\n",
       "      <th>frac_agrc_cereals_cl2_dry</th>\n",
       "      <th>frac_agrc_cereals_cl2_wet</th>\n",
       "      <th>...</th>\n",
       "      <th>frac_frst_secondary_cl1_temperate_nutrient_rich</th>\n",
       "      <th>frac_frst_secondary_cl1_tropical</th>\n",
       "      <th>frac_lndu_grasslands_cl1_temperate</th>\n",
       "      <th>frac_lndu_grasslands_cl1_tropical</th>\n",
       "      <th>frac_lndu_grasslands_cl2_dry</th>\n",
       "      <th>frac_lndu_grasslands_cl2_wet</th>\n",
       "      <th>frac_lndu_other_cl2_dry</th>\n",
       "      <th>frac_lndu_other_cl2_wet</th>\n",
       "      <th>frac_lndu_settlements_cl2_dry</th>\n",
       "      <th>frac_lndu_settlements_cl2_wet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>31</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494863</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>32</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494863</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>33</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494863</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7630</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>34</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494863</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7631</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494863</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7632 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country  time_period  frac_agrc_bevs_and_spices_cl1_temperate  \\\n",
       "0        ABW            0                                 1.000000   \n",
       "1        ABW            1                                 1.000000   \n",
       "2        ABW            2                                 1.000000   \n",
       "3        ABW            3                                 1.000000   \n",
       "4        ABW            4                                 1.000000   \n",
       "...      ...          ...                                      ...   \n",
       "7627     ZWE           31                                 0.989726   \n",
       "7628     ZWE           32                                 0.989726   \n",
       "7629     ZWE           33                                 0.989726   \n",
       "7630     ZWE           34                                 0.989726   \n",
       "7631     ZWE           35                                 0.989726   \n",
       "\n",
       "      frac_agrc_bevs_and_spices_cl1_tropical  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.000000   \n",
       "2                                   0.000000   \n",
       "3                                   0.000000   \n",
       "4                                   0.000000   \n",
       "...                                      ...   \n",
       "7627                                0.010274   \n",
       "7628                                0.010274   \n",
       "7629                                0.010274   \n",
       "7630                                0.010274   \n",
       "7631                                0.010274   \n",
       "\n",
       "      frac_agrc_bevs_and_spices_cl2_dry  frac_agrc_bevs_and_spices_cl2_wet  \\\n",
       "0                              1.000000                           0.000000   \n",
       "1                              1.000000                           0.000000   \n",
       "2                              1.000000                           0.000000   \n",
       "3                              1.000000                           0.000000   \n",
       "4                              1.000000                           0.000000   \n",
       "...                                 ...                                ...   \n",
       "7627                           0.989726                           0.010274   \n",
       "7628                           0.989726                           0.010274   \n",
       "7629                           0.989726                           0.010274   \n",
       "7630                           0.989726                           0.010274   \n",
       "7631                           0.989726                           0.010274   \n",
       "\n",
       "      frac_agrc_cereals_cl1_temperate  frac_agrc_cereals_cl1_tropical  \\\n",
       "0                            1.000000                        0.000000   \n",
       "1                            1.000000                        0.000000   \n",
       "2                            1.000000                        0.000000   \n",
       "3                            1.000000                        0.000000   \n",
       "4                            1.000000                        0.000000   \n",
       "...                               ...                             ...   \n",
       "7627                         0.989726                        0.010274   \n",
       "7628                         0.989726                        0.010274   \n",
       "7629                         0.989726                        0.010274   \n",
       "7630                         0.989726                        0.010274   \n",
       "7631                         0.989726                        0.010274   \n",
       "\n",
       "      frac_agrc_cereals_cl2_dry  frac_agrc_cereals_cl2_wet  ...  \\\n",
       "0                      1.000000                   0.000000  ...   \n",
       "1                      1.000000                   0.000000  ...   \n",
       "2                      1.000000                   0.000000  ...   \n",
       "3                      1.000000                   0.000000  ...   \n",
       "4                      1.000000                   0.000000  ...   \n",
       "...                         ...                        ...  ...   \n",
       "7627                   0.989726                   0.010274  ...   \n",
       "7628                   0.989726                   0.010274  ...   \n",
       "7629                   0.989726                   0.010274  ...   \n",
       "7630                   0.989726                   0.010274  ...   \n",
       "7631                   0.989726                   0.010274  ...   \n",
       "\n",
       "      frac_frst_secondary_cl1_temperate_nutrient_rich  \\\n",
       "0                                            0.500000   \n",
       "1                                            0.500000   \n",
       "2                                            0.500000   \n",
       "3                                            0.500000   \n",
       "4                                            0.500000   \n",
       "...                                               ...   \n",
       "7627                                         0.494863   \n",
       "7628                                         0.494863   \n",
       "7629                                         0.494863   \n",
       "7630                                         0.494863   \n",
       "7631                                         0.494863   \n",
       "\n",
       "      frac_frst_secondary_cl1_tropical  frac_lndu_grasslands_cl1_temperate  \\\n",
       "0                             0.000000                            1.000000   \n",
       "1                             0.000000                            1.000000   \n",
       "2                             0.000000                            1.000000   \n",
       "3                             0.000000                            1.000000   \n",
       "4                             0.000000                            1.000000   \n",
       "...                                ...                                 ...   \n",
       "7627                          0.010274                            0.989726   \n",
       "7628                          0.010274                            0.989726   \n",
       "7629                          0.010274                            0.989726   \n",
       "7630                          0.010274                            0.989726   \n",
       "7631                          0.010274                            0.989726   \n",
       "\n",
       "      frac_lndu_grasslands_cl1_tropical  frac_lndu_grasslands_cl2_dry  \\\n",
       "0                              0.000000                      1.000000   \n",
       "1                              0.000000                      1.000000   \n",
       "2                              0.000000                      1.000000   \n",
       "3                              0.000000                      1.000000   \n",
       "4                              0.000000                      1.000000   \n",
       "...                                 ...                           ...   \n",
       "7627                           0.010274                      0.989726   \n",
       "7628                           0.010274                      0.989726   \n",
       "7629                           0.010274                      0.989726   \n",
       "7630                           0.010274                      0.989726   \n",
       "7631                           0.010274                      0.989726   \n",
       "\n",
       "      frac_lndu_grasslands_cl2_wet  frac_lndu_other_cl2_dry  \\\n",
       "0                         0.000000                 1.000000   \n",
       "1                         0.000000                 1.000000   \n",
       "2                         0.000000                 1.000000   \n",
       "3                         0.000000                 1.000000   \n",
       "4                         0.000000                 1.000000   \n",
       "...                            ...                      ...   \n",
       "7627                      0.010274                 0.989726   \n",
       "7628                      0.010274                 0.989726   \n",
       "7629                      0.010274                 0.989726   \n",
       "7630                      0.010274                 0.989726   \n",
       "7631                      0.010274                 0.989726   \n",
       "\n",
       "      frac_lndu_other_cl2_wet  frac_lndu_settlements_cl2_dry  \\\n",
       "0                    0.000000                       1.000000   \n",
       "1                    0.000000                       1.000000   \n",
       "2                    0.000000                       1.000000   \n",
       "3                    0.000000                       1.000000   \n",
       "4                    0.000000                       1.000000   \n",
       "...                       ...                            ...   \n",
       "7627                 0.010274                       0.989726   \n",
       "7628                 0.010274                       0.989726   \n",
       "7629                 0.010274                       0.989726   \n",
       "7630                 0.010274                       0.989726   \n",
       "7631                 0.010274                       0.989726   \n",
       "\n",
       "      frac_lndu_settlements_cl2_wet  \n",
       "0                          0.000000  \n",
       "1                          0.000000  \n",
       "2                          0.000000  \n",
       "3                          0.000000  \n",
       "4                          0.000000  \n",
       "...                             ...  \n",
       "7627                       0.010274  \n",
       "7628                       0.010274  \n",
       "7629                       0.010274  \n",
       "7630                       0.010274  \n",
       "7631                       0.010274  \n",
       "\n",
       "[7632 rows x 71 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for var_name in varlist_soc:\n",
    "    df_agg_all_fields[var_name] = np.array(df_agg_all_fields[field_cp])\n",
    "\n",
    "df_agg_all_fields.drop(field_cp, axis = 1, inplace = True)\n",
    "df_agg_all_fields.rename(columns = {field_en: field_country}, inplace = True)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
